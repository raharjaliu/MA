{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import copy\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sys import getsizeof\n",
    "\n",
    "import cv2\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiffcapture as tc\n",
    "\n",
    "from tifffile import imsave\n",
    "from matplotlib import pyplot as pt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSITION = 40\n",
    "PROCESS_PI = False\n",
    "TIME_UNIT_FACTOR = 600\n",
    "PIXEL_INCH_RATIO = .647\n",
    "DIAMETER = 15\n",
    "SYNCHRONIZED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removekey(d, key):\n",
    "    \"\"\"\n",
    "    Remove a key from a  dictionary without destroying the reference\n",
    "    to removed object (which might be used by other processes)\n",
    "    \"\"\"\n",
    "    if key in d:\n",
    "        r = dict(d)\n",
    "        del r[key]\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_trees(links_tab, verbose=False, parse_velocity_displacement=False):\n",
    "    \"\"\"\n",
    "    Given 'links in tab statistics' from TrackMate.\n",
    "    Construct data structures representing trees ('tree') and\n",
    "    their branching ('branch') respectively.\n",
    "    \n",
    "    -   'tree' contains mapping of TREE_ID (which is the same as\n",
    "        the id of root's SPOT_ID) to its associated tree.\n",
    "        Each tree is in turn a map of TREE_BRANCH_ID\n",
    "        (which is the branch's first spot's SPOT_ID)\n",
    "        to its branch which is represented as list of SPOT_ID's.\n",
    "    -   'branch' encodes how the tree is structured. It contains\n",
    "        mapping of TREE_ID to the branching configuration.\n",
    "        The branching configuration is encoded as mapping of\n",
    "        BRANCH_ID to its two children's BRANCH_ID.\n",
    "    \"\"\"\n",
    "    \n",
    "    links_tab = links_tab.copy()\n",
    "    links_tab.index = links_tab.SPOT_TARGET_ID\n",
    "\n",
    "    tree = {}\n",
    "    branch = {}\n",
    "    if parse_velocity_displacement:\n",
    "        velocity = {}\n",
    "        displacement = {}\n",
    "        \n",
    "    for track in links_tab.TRACK_ID.unique():\n",
    "    \n",
    "        sub = links_tab[links_tab.TRACK_ID == track]\n",
    "\n",
    "        this_lines = {}\n",
    "        this_branches = {}\n",
    "        if parse_velocity_displacement:\n",
    "            this_velocities = {}\n",
    "            this_displacements = {}\n",
    "        stack = []\n",
    "    \n",
    "        groot = sub.iloc[0][3]\n",
    "        if verbose:\n",
    "            print(\"Parsing tree %s\" % groot)\n",
    "        stack.append(groot)\n",
    "    \n",
    "        while len(stack) > 0:\n",
    "        \n",
    "            root = stack.pop()\n",
    "            track = [root]\n",
    "            if parse_velocity_displacement:\n",
    "                # initial velocity and displacement is always 0\n",
    "                vel = [0]\n",
    "                disp = [0]\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Parsing subtree %s\" % root)\n",
    "            nsub = sub[sub.SPOT_SOURCE_ID == root]\n",
    "        \n",
    "            while nsub.index.size > 0:\n",
    "                if nsub.index.size == 1:\n",
    "                    this = nsub.iloc[0][4]\n",
    "                    track.append(this)\n",
    "                    if parse_velocity_displacement:\n",
    "                        ## TODO check whether the implementation is correct\n",
    "                        if len(sub.loc[this]) == 13:\n",
    "                            vel.append(sub.loc[this]['VELOCITY'])\n",
    "                            disp.append(sub.loc[this]['DISPLACEMENT'])\n",
    "                        else:\n",
    "                            vel.append(sub.loc[this]['VELOCITY'].values[0])\n",
    "                            disp.append(sub.loc[this]['DISPLACEMENT'].values[0])\n",
    "                    nsub = sub[sub.SPOT_SOURCE_ID == this]\n",
    "                else:\n",
    "                    stack.append(nsub.iloc[0][4])\n",
    "                    stack.append(nsub.iloc[1][4])\n",
    "                    this_branches[root] = (nsub.iloc[0][4], nsub.iloc[1][4])\n",
    "                    if verbose:\n",
    "                        print(\"breaking\")\n",
    "                    break\n",
    "                \n",
    "            this_lines[root] = track\n",
    "            if parse_velocity_displacement:\n",
    "                this_velocities[root] = vel\n",
    "                this_displacements[root] = disp\n",
    "            if verbose:\n",
    "                print(\"adding branch %s\" % root)\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"Finishing...\")\n",
    "        tree[groot] = this_lines\n",
    "        branch[groot] = this_branches\n",
    "        if parse_velocity_displacement:\n",
    "            velocity[groot] = this_velocities\n",
    "            displacement[groot] = this_displacements\n",
    "        \n",
    "    if parse_velocity_displacement:\n",
    "        return tree, branch, velocity, displacement\n",
    "    else:\n",
    "        return tree, branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_values(tree, spots_tab, colnames, verbose=False):\n",
    "    \"\"\"\n",
    "    Extract varoius measurement values from spots statistics and save it\n",
    "    in format similar to parsed tree. The list of values to be extracted\n",
    "    from spots statistics is defined in 'colnames' \n",
    "    \n",
    "    The information will be stored in following format:\n",
    "    map(TYPE:(TREE_ID:TREE_BRANCH:list(VALUES))\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    vals = {}\n",
    "\n",
    "    for tr in tree:\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"extracting values for %s\" % tr)\n",
    "    \n",
    "        for colname in colnames:\n",
    "        \n",
    "            val_tree = {}\n",
    "        \n",
    "            for br in tree[tr]:\n",
    "            \n",
    "                brkeys = tree[tr][br]\n",
    "                brvals = [sits[sits.ID == x][colname].values[0] for x in brkeys]\n",
    "            \n",
    "                val_tree[br] = brvals\n",
    "            \n",
    "            if colname not in vals:\n",
    "                vals[colname] = {}\n",
    "            \n",
    "            vals[colname][tr] = val_tree\n",
    "            \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_trees_by_time(tree, branch, tree_values, min_time=0, max_time=10):\n",
    "    \"\"\"\n",
    "    Filter out trees which measurement time start before or after\n",
    "    the time as defined in 'min_time' and 'max_time'.\n",
    "    \n",
    "    Measurement time is defined as the return value from TrackMate\n",
    "    encoded as 'POSITION_T'\n",
    "    \"\"\"\n",
    "    \n",
    "    tree_values_filtered = {}\n",
    "    tree = copy.deepcopy(tree)\n",
    "    branch = copy.deepcopy(branch)\n",
    "\n",
    "    for v in tree_values.keys():\n",
    "        tree_values_filtered[v] = {}\n",
    "\n",
    "    for key in tree_values['POSITION_T'].keys():\n",
    "    \n",
    "        if (tree_values['POSITION_T'][key][key][0] >= min_time) and (tree_values['POSITION_T'][key][key][0] <= max_time):\n",
    "            for k in tree_values_filtered.keys():\n",
    "                tree_values_filtered[k][key] = tree_values[k][key]\n",
    "        else:\n",
    "            tree = removekey(tree, key)\n",
    "            branch = removekey(branch, key)\n",
    "                \n",
    "    return  tree, branch, tree_values_filtered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video(path, to_rgb=False):\n",
    "    \"\"\"\n",
    "    Read TIFF file containing multiple stacks (a video)\n",
    "    and return sequential array of frame encoded as\n",
    "    multidimensional array\n",
    "    \"\"\"\n",
    "    \n",
    "    tif = tc.opentiff(path)\n",
    "    \n",
    "    ## first image\n",
    "    _, first_img = tif.retrieve()\n",
    "    if to_rgb:\n",
    "        first_img = cv2.cvtColor(first_img,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    ## slices\n",
    "    pics = [first_img]\n",
    "\n",
    "    for slide in tif:\n",
    "        # convert grayscale to RGB\n",
    "        if to_rgb:\n",
    "            slide = cv2.cvtColor(slide, cv2.COLOR_GRAY2RGB)\n",
    "        pics.append(slide)\n",
    "    \n",
    "    return pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_brightness(tree_id, \n",
    "                       tree, \n",
    "                       tree_values, \n",
    "                       reference_vid_path, \n",
    "                       diameter=DIAMETER, \n",
    "                       caspase=True, \n",
    "                       normalize=True, \n",
    "                       synchronized=False):\n",
    "    \"\"\"\n",
    "    Given cell death signal video, extract brightness level for each position\n",
    "    of tracked cell trees, if such poisition coincides with the.\n",
    "    \n",
    "    This function returns:\n",
    "    -   the brightness level of each spot in the tree, if such is measured.\n",
    "        The encoding follows that of the tree itself\n",
    "    -   cell death signal time-lapsed video of containing the cell belonging\n",
    "        to the 'tree_id'. Useful for debugging/sanity testing \n",
    "    \"\"\"\n",
    "    \n",
    "    pics = get_video(reference_vid_path)\n",
    "    pics_intersect = []\n",
    "\n",
    "    t_time = tree_values['POSITION_T'][tree_id] # tree_values\n",
    "    t_x = tree_values['POSITION_X'][tree_id]\n",
    "    t_y = tree_values['POSITION_Y'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "\n",
    "    t_brightness = {}\n",
    "    \n",
    "    if normalize:\n",
    "        base_brightness = []\n",
    "        for pic in pics:\n",
    "            base_brightness.append(cv2.sumElems(pic)[0] / float(pic.shape[0] * pic.shape[1]))\n",
    "\n",
    "    for br in t_tree:\n",
    "        brch = t_tree[br]\n",
    "        x = t_x[br]\n",
    "        y = t_y[br]\n",
    "        time = t_time[br]\n",
    "        brightness = []\n",
    "    \n",
    "        for i in range(len(brch)):\n",
    "            if synchronized or (not caspase):\n",
    "                if time[i] % 1800 == 0:\n",
    "                    pos = time[i] // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)     \n",
    "            else:\n",
    "                if ((time[i] - 76200) >= 0) & ((time[i] - 76200) % 1800 == 0):\n",
    "                    pos = (time[i] - 76200) // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)\n",
    "            \n",
    "        t_brightness[br] = brightness\n",
    "    return t_brightness, np.array(pics_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_brightness_template(tree_id, \n",
    "                                tree, \n",
    "                                tree_values, \n",
    "                                pics, \n",
    "                                diameter=DIAMETER, \n",
    "                                caspase=True, \n",
    "                                normalize=True,\n",
    "                                synchronized=False):\n",
    "    \"\"\"\n",
    "    Similar to extract_brightness(), except that it\n",
    "    takes video template form the user\n",
    "    \n",
    "    This function returns:\n",
    "    -   the brightness level of each spot in the tree, if such is measured.\n",
    "        The encoding follows that of the tree itself\n",
    "    -   cell death signal time-lapsed video of containing the cell belonging\n",
    "        to the 'tree_id'. Useful for debugging/sanity testing \n",
    "    \"\"\"\n",
    "    \n",
    "    pics_intersect = []\n",
    "\n",
    "    t_time = tree_values['POSITION_T'][tree_id] # tree_values\n",
    "    t_x = tree_values['POSITION_X'][tree_id]\n",
    "    t_y = tree_values['POSITION_Y'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "\n",
    "    t_brightness = {}\n",
    "    \n",
    "    if normalize:\n",
    "        base_brightness = []\n",
    "        for pic in pics:\n",
    "            base_brightness.append(cv2.sumElems(pic)[0] / float(pic.shape[0] * pic.shape[1]))\n",
    "\n",
    "    for br in t_tree:\n",
    "        brch = t_tree[br]\n",
    "        x = t_x[br]\n",
    "        y = t_y[br]\n",
    "        time = t_time[br]\n",
    "        brightness = []\n",
    "    \n",
    "        for i in range(len(brch)):\n",
    "            if synchronized or (not caspase):\n",
    "                if time[i] % 1800 == 0:\n",
    "                    pos = time[i] // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)\n",
    "            else:\n",
    "                if ((time[i] - 76200) >= 0) & ((time[i] - 76200) % 1800 == 0):\n",
    "                    pos = (time[i] - 76200) // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)\n",
    "            \n",
    "        t_brightness[br] = brightness\n",
    "    return t_brightness, np.array(pics_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_tree_to_contours(tree_values, contours):\n",
    "    \"\"\"\n",
    "    Given tree values and recognized contours, compute:\n",
    "    \n",
    "    -   'assocs': table listing recognized slit and the TREE_ID\n",
    "        of singly-placed cell tree located in the slit\n",
    "    -   'occupancy': list containing the number of cell trees\n",
    "        located in a slit. NOTE: the list is not associated with\n",
    "        ordering encoded in 'assocs'\n",
    "    \"\"\"\n",
    "\n",
    "    occuppancy = {x:0 for x in range(len(contours))}\n",
    "    cell_trees = []\n",
    "    slits = []\n",
    "\n",
    "    for tr in tree_values['POSITION_X'].keys():\n",
    "    \n",
    "        cell_trees.append(tr)\n",
    "\n",
    "        x = tree_values['POSITION_X'][tr][tr][0] / PIXEL_INCH_RATIO\n",
    "        y = tree_values['POSITION_Y'][tr][tr][0] / PIXEL_INCH_RATIO\n",
    "    \n",
    "        counter = 0\n",
    "        match = 0\n",
    "        matchloc = None\n",
    "    \n",
    "        for ct in cts:\n",
    "        \n",
    "            if cv2.pointPolygonTest(ct, (x, y), False) > 0:\n",
    "                occuppancy[counter] += 1\n",
    "                matchloc = counter\n",
    "                match += 1\n",
    "            counter +=  1\n",
    "        \n",
    "        if match == 0:\n",
    "            slits.append(None)\n",
    "        elif match == 1:\n",
    "            slits.append(matchloc)\n",
    "        else:\n",
    "            print(\"Tree %s got too many matches\" % tr)\n",
    "        \n",
    "    assocs = pd.DataFrame({'CELL_LINE': cell_trees, 'SLIT_ID': slits})\n",
    "    occuppancy = np.array(list(occuppancy.values()))\n",
    "    \n",
    "    return assocs, occuppancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_contour(contour_mask_path, min_size=7000, max_size=10000):\n",
    "    \"\"\"\n",
    "    Give contour mask picture (created by adjusting contrast/brightness\n",
    "    followed by RATS and \"fill holes\" command) detect contours of\n",
    "    slits annd return:\n",
    "    - the list of filtered contours\n",
    "    - the size list of filtered contours\n",
    "    - the size of all detected contours (for testing purpose)\n",
    "    \"\"\"\n",
    "    \n",
    "    ## collect contours and wrap into a function\n",
    "\n",
    "    im = cv2.imread(contour_mask_path)\n",
    "    gray= cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    im2, contours, hierarchy  = cv2.findContours(gray,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    all_cts_area = np.array([cv2.contourArea(x) for x  in contours])\n",
    "\n",
    "    filtered_cts = []\n",
    "    filtered_cts_area = []\n",
    "\n",
    "    for ct in contours:\n",
    "        ct_area = cv2.contourArea(ct)\n",
    "        if (ct_area <= max_size) and (ct_area >= min_size):\n",
    "            filtered_cts.append(ct)\n",
    "            filtered_cts_area.append(ct_area)\n",
    "            \n",
    "    return filtered_cts, filtered_cts_area, all_cts_area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTREE_ID:\\n    \"TREE\"\\n    \"BRANCH\"\\n    \"POSITION_T\"\\n    \"POSITION_X\"\\n    \"POSITION_Y\"\\n    \"CASPASE\"\\n    \"CASPASE_NORM\"\\n    \"CASPASE_SUB\"\\n    \"CASPASE_SUB_NORM\"\\n    \"PI\"\\n    \"PI_NORM\"\\n    \"PI_SUB\"\\n    \"PI_SUB_NORM\"\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TREE_ID:\n",
    "    \"TREE\"\n",
    "    \"BRANCH\"\n",
    "    \"POSITION_T\"\n",
    "    \"POSITION_X\"\n",
    "    \"POSITION_Y\"\n",
    "    \"CASPASE\"\n",
    "    \"CASPASE_NORM\"\n",
    "    \"CASPASE_SUB\"\n",
    "    \"CASPASE_SUB_NORM\"\n",
    "    \"PI\"\n",
    "    \"PI_NORM\"\n",
    "    \"PI_SUB\"\n",
    "    \"PI_SUB_NORM\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "done = []\n",
    "dat = {}\n",
    "dat_f = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positions = list(set(list(range(64)[1:])) - set([12, 26, 37, 38, 44, 60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing position 01...\n",
      "  Reading files\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "File b'E:/sync_processed/eli-new-sync-bf-01/out-focus/out/tracked/Links in tracks statistics.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f701c8bb859f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpi_sub_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"E:/sync_processed/eli-new-sync-bf-%s/pi/sub.tif\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Links in tracks statistics.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0msits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Spots in tracks statistics.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"  Reading files done. Time elapsed: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'E:/sync_processed/eli-new-sync-bf-01/out-focus/out/tracked/Links in tracks statistics.csv' does not exist"
     ]
    }
   ],
   "source": [
    "## TODO: continue\n",
    "\n",
    "diameter = 15\n",
    "\n",
    "for position in positions:\n",
    "    \n",
    "    if position < 10:\n",
    "        pos = \"0%d\" % position\n",
    "    else:\n",
    "        pos = str(position)\n",
    "    \n",
    "    if position not in done:\n",
    "\n",
    "\n",
    "        t = time.time()\n",
    "        print(\"Processing position %s...\\n  Reading files\" % pos)\n",
    "\n",
    "#         track_path = \"../test/eli-new-sync-bf-%s/out-focus/out/tracked/\" % pos\n",
    "#         caspase_path = \"../test/eli-new-sync-bf-%s/caspase/seq0001xy%sc1.tif\" % (pos, pos)\n",
    "#         caspase_sub_path = \"../test/eli-new-sync-bf-%s/caspase/seq0001xy%sc1_sub.tif\" % (pos, pos)\n",
    "#         pi_path = \"../test/eli-new-sync-bf-%s/pi/seq0002xy%sc1.tif\" % (pos, pos)\n",
    "#         pi_sub_path = \"../test/eli-new-sync-bf-%s/pi/sub.tif\" % pos\n",
    "        \n",
    "        track_path = \"E:/sync_processed/eli-new-sync-bf-%s/out-focus/out/tracked/\" % pos\n",
    "        caspase_path = \"E:/sync_processed/eli-new-sync-bf-%s/caspase/seq0001xy%sc1.tif\" % (pos, pos)\n",
    "        caspase_sub_path = \"E:/sync_processed/eli-new-sync-bf-%s/caspase/seq0001xy%sc1_sub.tif\" % (pos, pos)\n",
    "        pi_path = \"E:/sync_processed/eli-new-sync-bf-%s/pi/seq0002xy%sc1.tif\" % (pos, pos)\n",
    "        pi_sub_path = \"E:/sync_processed/eli-new-sync-bf-%s/pi/sub.tif\" % pos\n",
    "\n",
    "        ba = pd.read_csv(os.path.join(track_path, 'Links in tracks statistics.csv'))\n",
    "        sits = pd.read_csv(os.path.join(track_path, 'Spots in tracks statistics.csv'))\n",
    "        print(\"  Reading files done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        ## parsing tree\n",
    "        t = time.time()\n",
    "        print(\"  Parsing trees and values\")\n",
    "        tree, branch, velocity, displacement = parse_trees(ba, parse_velocity_displacement=True)\n",
    "        svals = extract_values(tree, sits, ['POSITION_T', 'POSITION_X', 'POSITION_Y', 'TOTAL_INTENSITY', 'QUALITY'])\n",
    "        print(\"  Parsing done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        ## filter tree\n",
    "\n",
    "        t = time.time()\n",
    "        print(\"  Filtering tree\")\n",
    "        tree, branch, svals = filter_trees_by_time(tree, branch, svals)\n",
    "        print(\"  Filtering done. Time elapsed: %f\" % (time.time() - t))\n",
    "        \n",
    "        ## extract cell association\n",
    "        t = time.time()\n",
    "        print(\"  Getting contour\")\n",
    "        \n",
    "#         path = \"../test/sync_processed/eli-new-sync-bf-%s/in-focus/\" % pos\n",
    "        path = \"E:/sync_processed/eli-new-sync-bf-%s/in-focus/\" % pos\n",
    "        impath = \"seq0000xy%sc1-mask.tif\" % pos\n",
    "        \n",
    "        cts, _, _ = get_contour(os.path.join(path, impath))\n",
    "        assocs, _ = assign_tree_to_contours(svals, cts)\n",
    "        cell_trees = set(assocs.CELL_LINE[~assocs.SLIT_ID.isnull()].tolist())\n",
    "\n",
    "        print(\"  Contour recognition done. Time elapsed: %f\" % (time.time() - t))\n",
    "        ## extract cas + pi value\n",
    "\n",
    "        print(\"  Extarcting caspase and pi measurement values\")\n",
    "        t = time.time()\n",
    "        caspases = {}\n",
    "        caspases_norm = {}\n",
    "        caspases_sub = {}\n",
    "        caspases_sub_norm = {}\n",
    "        pis = {}\n",
    "        pis_norm = {}\n",
    "        pis_sub = {}\n",
    "        pis_sub_norm = {}\n",
    "    \n",
    "        pics_casp = get_video(caspase_path)\n",
    "        pics_casp_sub = get_video(caspase_sub_path)\n",
    "        pics_pi = get_video(pi_path)\n",
    "        pics_pi_sub = get_video(pi_sub_path)\n",
    "    \n",
    "        for k in tree.keys():\n",
    "\n",
    "            cs, _ = extract_brightness_template(k, \n",
    "                                                tree, \n",
    "                                                svals, \n",
    "                                                pics_casp, \n",
    "                                                caspase=True,\n",
    "                                                normalize=False,\n",
    "                                                synchronized=SYNCHRONIZED)\n",
    "            caspases[k] = cs\n",
    "    \n",
    "            csnorm, _ = extract_brightness_template(k, \n",
    "                                                    tree, \n",
    "                                                    svals, \n",
    "                                                    pics_casp, \n",
    "                                                    caspase=True, \n",
    "                                                    normalize=True, \n",
    "                                                    synchronized=SYNCHRONIZED)\n",
    "            caspases_norm[k] = csnorm\n",
    "    \n",
    "            cssub, _ = extract_brightness_template(k, \n",
    "                                                   tree, \n",
    "                                                   svals, \n",
    "                                                   pics_casp_sub, \n",
    "                                                   caspase=True,\n",
    "                                                   normalize=False,\n",
    "                                                   synchronized=SYNCHRONIZED)\n",
    "            caspases_sub[k] = cssub\n",
    "    \n",
    "            cssubnorm, _ = extract_brightness_template(k, \n",
    "                                                       tree, \n",
    "                                                       svals, \n",
    "                                                       pics_casp_sub, \n",
    "                                                       caspase=True, \n",
    "                                                       normalize=True, \n",
    "                                                       synchronized=SYNCHRONIZED)\n",
    "            caspases_sub_norm[k] = cssubnorm\n",
    "                \n",
    "    \n",
    "        print(\"  Extracting caspase done. Time elapsed: %f\" % (time.time() - t))\n",
    "    \n",
    "        t = time.time()\n",
    "        for k in tree.keys():\n",
    "    \n",
    "            pi, _ = extract_brightness_template(k, \n",
    "                                                tree, \n",
    "                                                svals, \n",
    "                                                pics_pi, \n",
    "                                                caspase=False, \n",
    "                                                normalize=False)\n",
    "            pis[k] = pi\n",
    "        \n",
    "            pinorm, _ = extract_brightness_template(k, \n",
    "                                                    tree, \n",
    "                                                    svals, \n",
    "                                                    pics_pi, \n",
    "                                                    caspase=False, \n",
    "                                                    normalize=True)\n",
    "            pis_norm[k] = pinorm\n",
    "        \n",
    "            pisub, _ = extract_brightness_template(k, \n",
    "                                                   tree, \n",
    "                                                   svals, \n",
    "                                                   pics_pi_sub, \n",
    "                                                   caspase=False, \n",
    "                                                   normalize=False)\n",
    "            pis_sub[k] = pisub\n",
    "        \n",
    "            pisubnorm, _ = extract_brightness_template(k, \n",
    "                                                       tree, \n",
    "                                                       svals, \n",
    "                                                       pics_pi_sub, \n",
    "                                                       caspase=False, \n",
    "                                                       normalize=True)\n",
    "            pis_sub_norm[k] = pisubnorm\n",
    "    \n",
    "        print(\"  Extracting pi done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        print(\"  Wrapping values\")\n",
    "        t = time.time()\n",
    "        \n",
    "        pos_dat = {}\n",
    "        pos_dat_f = {}\n",
    "        pos_dat_trees = {}\n",
    "        pos_dat_trees_f = {}        \n",
    "        for tr in tree.keys():\n",
    "            t_tree = {\n",
    "                \"TREE\": tree[tr],\n",
    "                \"BRANCH\": branch[tr],\n",
    "                \"POSITION_T\": svals[\"POSITION_T\"][tr],\n",
    "                \"POSITION_X\": svals[\"POSITION_X\"][tr],\n",
    "                \"POSITION_Y\": svals[\"POSITION_Y\"][tr],\n",
    "                \"CASPASE\": caspases[tr],\n",
    "                \"CASPASE_NORM\": caspases_norm[tr],\n",
    "                \"CASPASE_SUB\": caspases_sub[tr],\n",
    "                \"CASPASE_SUB_NORM\": caspases_sub_norm[tr],\n",
    "                \"PI\": pis[tr],\n",
    "                \"PI_NORM\": pis_norm[tr],\n",
    "                \"PI_SUB\": pis_sub[tr],\n",
    "                \"PI_SUB_NORM\": pis_sub_norm[tr],\n",
    "                \"VELOCITY\": velocity[tr],\n",
    "                \"DISPLACEMENT\": displacement[tr]\n",
    "            }\n",
    "            if tr in cell_trees:\n",
    "                pos_dat_trees_f[tr] = t_tree\n",
    "                pos_dat_trees[tr] = t_tree\n",
    "            else:\n",
    "                pos_dat_trees[tr] = t_tree\n",
    "    \n",
    "        pos_dat[\"TREES\"] = pos_dat_trees\n",
    "        pos_dat[\"GAP_PER_FRAME_SECONDS\"] = 600\n",
    "        pos_dat[\"PIXEL_TO_INCH\"] = 1 / .647\n",
    "        dat[pos] = pos_dat\n",
    "        \n",
    "        pos_dat_f[\"TREES\"] = pos_dat_trees_f\n",
    "        pos_dat_f[\"GAP_PER_FRAME_SECONDS\"] = 600\n",
    "        pos_dat_f[\"PIXEL_TO_INCH\"] = 1 / .647\n",
    "        dat_f[pos] = pos_dat_f\n",
    "        \n",
    "        done.append(position)\n",
    "        \n",
    "        for tree_id in cell_trees:    \n",
    "            dat_f[pos][\"TREES\"][tree_id][\"SLIT_ID\"] = int(assocs[assocs.CELL_LINE == tree_id][\"SLIT_ID\"].values[0])\n",
    "\n",
    "        print(\"  Extraction done. Time elapsed: %f\" % (time.time() - t))\n",
    "    else:\n",
    "        print(\"  Position %s already extracted\" % pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making filtered data JSON compliant and export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat_c = copy.deepcopy(dat)\n",
    "dat_fc = copy.deepcopy(dat_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Making dat JSON compliant\")\n",
    "for pos in dat_c.keys():\n",
    "    t = time.time()\n",
    "    print(\"  Doing position %s\" % pos)\n",
    "\n",
    "    for tid in dat_c[pos]['TREES'].keys():\n",
    "    ## change value of single tree\n",
    "        dat_c[pos]['TREES'][tid]['BRANCH'] = {str(k):(int(v[0]), int(v[1])) for k,v in dat_c[pos]['TREES'][tid]['BRANCH'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['TREE'] = {str(k):[int(val) for val in v] for k,v in dat_c[pos]['TREES'][tid]['TREE'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['POSITION_T'] = {str(k):[int(val) for val in v] for k,v in dat_c[pos]['TREES'][tid]['POSITION_T'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['POSITION_X'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['POSITION_X'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['POSITION_Y'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['POSITION_Y'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['CASPASE'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['CASPASE'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['CASPASE_NORM'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['CASPASE_NORM'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['CASPASE_SUB'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['CASPASE_SUB'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['CASPASE_SUB_NORM'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['CASPASE_SUB_NORM'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['PI'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['PI'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['PI_NORM'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['PI_NORM'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['PI_SUB'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['PI_SUB'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['PI_SUB_NORM'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['PI_SUB_NORM'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['VELOCITY'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['VELOCITY'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['DISPLACEMENT'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['DISPLACEMENT'].items()}\n",
    "\n",
    "    ## change value of trees\n",
    "    dat_c[pos]['TREES'] = {str(k):v for k,v in dat_c[pos]['TREES'].items()}\n",
    "    \n",
    "    print(\"  Finished. Time: %f\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Making dat JSON compliant\")\n",
    "for pos in dat_fc.keys():\n",
    "    t = time.time()\n",
    "    print(\"  Doing position %s\" % pos)\n",
    "\n",
    "    for tid in dat_fc[pos]['TREES'].keys():\n",
    "    ## change value of single tree\n",
    "        dat_fc[pos]['TREES'][tid]['BRANCH'] = {str(k):(int(v[0]), int(v[1])) for k,v in dat_fc[pos]['TREES'][tid]['BRANCH'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['TREE'] = {str(k):[int(val) for val in v] for k,v in dat_fc[pos]['TREES'][tid]['TREE'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['POSITION_T'] = {str(k):[int(val) for val in v] for k,v in dat_fc[pos]['TREES'][tid]['POSITION_T'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['POSITION_X'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['POSITION_X'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['POSITION_Y'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['POSITION_Y'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['CASPASE'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['CASPASE'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['CASPASE_NORM'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['CASPASE_NORM'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['CASPASE_SUB'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['CASPASE_SUB'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['CASPASE_SUB_NORM'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['CASPASE_SUB_NORM'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['PI'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['PI'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['PI_NORM'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['PI_NORM'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['PI_SUB'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['PI_SUB'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['PI_SUB_NORM'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['PI_SUB_NORM'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['VELOCITY'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['VELOCITY'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['DISPLACEMENT'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['DISPLACEMENT'].items()}\n",
    "\n",
    "    ## change value of trees\n",
    "    dat_fc[pos]['TREES'] = {str(k):v for k,v in dat_fc[pos]['TREES'].items()}\n",
    "    \n",
    "    print(\"  Finished. Time: %f\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../results/syn-filtered.json', 'w') as fp:\n",
    "    json.dump(dat_fc, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(dat_fc, open(\"../results/syn-filtered.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../results/syn-unfiltered.json', 'w') as fp:\n",
    "    json.dump(dat_c, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dat_c, open(\"../results/syn-unfiltered.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
