{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import copy\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sys import getsizeof\n",
    "\n",
    "import cv2\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiffcapture as tc\n",
    "\n",
    "from tifffile import imsave\n",
    "from matplotlib import pyplot as pt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSITION = 40\n",
    "PROCESS_PI = False\n",
    "TIME_UNIT_FACTOR = 600\n",
    "PIXEL_INCH_RATIO = .647\n",
    "DIAMETER = 15\n",
    "SYNCHRONIZED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removekey(d, key):\n",
    "    \"\"\"\n",
    "    Remove a key from a  dictionary without destroying the reference\n",
    "    to removed object (which might be used by other processes)\n",
    "    \"\"\"\n",
    "    if key in d:\n",
    "        r = dict(d)\n",
    "        del r[key]\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_trees(links_tab, verbose=False, parse_velocity_displacement=False):\n",
    "    \"\"\"\n",
    "    Given 'links in tab statistics' from TrackMate.\n",
    "    Construct data structures representing trees ('tree') and\n",
    "    their branching ('branch') respectively.\n",
    "    \n",
    "    -   'tree' contains mapping of TREE_ID (which is the same as\n",
    "        the id of root's SPOT_ID) to its associated tree.\n",
    "        Each tree is in turn a map of TREE_BRANCH_ID\n",
    "        (which is the branch's first spot's SPOT_ID)\n",
    "        to its branch which is represented as list of SPOT_ID's.\n",
    "    -   'branch' encodes how the tree is structured. It contains\n",
    "        mapping of TREE_ID to the branching configuration.\n",
    "        The branching configuration is encoded as mapping of\n",
    "        BRANCH_ID to its two children's BRANCH_ID.\n",
    "    \"\"\"\n",
    "    \n",
    "    links_tab = links_tab.copy()\n",
    "    links_tab.index = links_tab.SPOT_TARGET_ID\n",
    "\n",
    "    tree = {}\n",
    "    branch = {}\n",
    "    if parse_velocity_displacement:\n",
    "        velocity = {}\n",
    "        displacement = {}\n",
    "        \n",
    "    for track in links_tab.TRACK_ID.unique():\n",
    "    \n",
    "        sub = links_tab[links_tab.TRACK_ID == track]\n",
    "\n",
    "        this_lines = {}\n",
    "        this_branches = {}\n",
    "        if parse_velocity_displacement:\n",
    "            this_velocities = {}\n",
    "            this_displacements = {}\n",
    "        stack = []\n",
    "    \n",
    "        groot = sub.iloc[0][3]\n",
    "        if verbose:\n",
    "            print(\"Parsing tree %s\" % groot)\n",
    "        stack.append(groot)\n",
    "    \n",
    "        while len(stack) > 0:\n",
    "        \n",
    "            root = stack.pop()\n",
    "            track = [root]\n",
    "            if parse_velocity_displacement:\n",
    "                # initial velocity and displacement is always 0\n",
    "                vel = [0]\n",
    "                disp = [0]\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Parsing subtree %s\" % root)\n",
    "            nsub = sub[sub.SPOT_SOURCE_ID == root]\n",
    "        \n",
    "            while nsub.index.size > 0:\n",
    "                if nsub.index.size == 1:\n",
    "                    this = nsub.iloc[0][4]\n",
    "                    track.append(this)\n",
    "                    if parse_velocity_displacement:\n",
    "                        vel.append(sub.loc[this]['VELOCITY'])\n",
    "                        disp.append(sub.loc[this]['DISPLACEMENT'])\n",
    "                    nsub = sub[sub.SPOT_SOURCE_ID == this]\n",
    "                else:\n",
    "                    stack.append(nsub.iloc[0][4])\n",
    "                    stack.append(nsub.iloc[1][4])\n",
    "                    this_branches[root] = (nsub.iloc[0][4], nsub.iloc[1][4])\n",
    "                    if verbose:\n",
    "                        print(\"breaking\")\n",
    "                    break\n",
    "                \n",
    "            this_lines[root] = track\n",
    "            if parse_velocity_displacement:\n",
    "                this_velocities[root] = vel\n",
    "                this_displacements[root] = disp\n",
    "            if verbose:\n",
    "                print(\"adding branch %s\" % root)\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"Finishing...\")\n",
    "        tree[groot] = this_lines\n",
    "        branch[groot] = this_branches\n",
    "        if parse_velocity_displacement:\n",
    "            velocity[groot] = this_velocities\n",
    "            displacement[groot] = this_displacements\n",
    "        \n",
    "    if parse_velocity_displacement:\n",
    "        return tree, branch, velocity, displacement\n",
    "    else:\n",
    "        return tree, branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_values(tree, spots_tab, colnames, verbose=False):\n",
    "    \"\"\"\n",
    "    Extract varoius measurement values from spots statistics and save it\n",
    "    in format similar to parsed tree. The list of values to be extracted\n",
    "    from spots statistics is defined in 'colnames' \n",
    "    \n",
    "    The information will be stored in following format:\n",
    "    map(TYPE:(TREE_ID:TREE_BRANCH:list(VALUES))\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    vals = {}\n",
    "\n",
    "    for tr in tree:\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"extracting values for %s\" % tr)\n",
    "    \n",
    "        for colname in colnames:\n",
    "        \n",
    "            val_tree = {}\n",
    "        \n",
    "            for br in tree[tr]:\n",
    "            \n",
    "                brkeys = tree[tr][br]\n",
    "                brvals = [sits[sits.ID == x][colname].values[0] for x in brkeys]\n",
    "            \n",
    "                val_tree[br] = brvals\n",
    "            \n",
    "            if colname not in vals:\n",
    "                vals[colname] = {}\n",
    "            \n",
    "            vals[colname][tr] = val_tree\n",
    "            \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_trees_by_time(tree, branch, tree_values, min_time=0, max_time=10):\n",
    "    \"\"\"\n",
    "    Filter out trees which measurement time start before or after\n",
    "    the time as defined in 'min_time' and 'max_time'.\n",
    "    \n",
    "    Measurement time is defined as the return value from TrackMate\n",
    "    encoded as 'POSITION_T'\n",
    "    \"\"\"\n",
    "    \n",
    "    tree_values_filtered = {}\n",
    "    tree = copy.deepcopy(tree)\n",
    "    branch = copy.deepcopy(branch)\n",
    "\n",
    "    for v in tree_values.keys():\n",
    "        tree_values_filtered[v] = {}\n",
    "\n",
    "    for key in tree_values['POSITION_T'].keys():\n",
    "    \n",
    "        if (tree_values['POSITION_T'][key][key][0] >= min_time) and (tree_values['POSITION_T'][key][key][0] <= max_time):\n",
    "            for k in tree_values_filtered.keys():\n",
    "                tree_values_filtered[k][key] = tree_values[k][key]\n",
    "        else:\n",
    "            tree = removekey(tree, key)\n",
    "            branch = removekey(branch, key)\n",
    "                \n",
    "    return  tree, branch, tree_values_filtered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video(path, to_rgb=False):\n",
    "    \"\"\"\n",
    "    Read TIFF file containing multiple stacks (a video)\n",
    "    and return sequential array of frame encoded as\n",
    "    multidimensional array\n",
    "    \"\"\"\n",
    "    \n",
    "    tif = tc.opentiff(path)\n",
    "    \n",
    "    ## first image\n",
    "    _, first_img = tif.retrieve()\n",
    "    if to_rgb:\n",
    "        first_img = cv2.cvtColor(first_img,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    ## slices\n",
    "    pics = [first_img]\n",
    "\n",
    "    for slide in tif:\n",
    "        # convert grayscale to RGB\n",
    "        if to_rgb:\n",
    "            slide = cv2.cvtColor(slide, cv2.COLOR_GRAY2RGB)\n",
    "        pics.append(slide)\n",
    "    \n",
    "    return pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_brightness(tree_id, \n",
    "                       tree, \n",
    "                       tree_values, \n",
    "                       reference_vid_path, \n",
    "                       diameter=DIAMETER, \n",
    "                       caspase=True, \n",
    "                       normalize=True, \n",
    "                       synchronized=False):\n",
    "    \"\"\"\n",
    "    Given cell death signal video, extract brightness level for each position\n",
    "    of tracked cell trees, if such poisition coincides with the.\n",
    "    \n",
    "    This function returns:\n",
    "    -   the brightness level of each spot in the tree, if such is measured.\n",
    "        The encoding follows that of the tree itself\n",
    "    -   cell death signal time-lapsed video of containing the cell belonging\n",
    "        to the 'tree_id'. Useful for debugging/sanity testing \n",
    "    \"\"\"\n",
    "    \n",
    "    pics = get_video(reference_vid_path)\n",
    "    pics_intersect = []\n",
    "\n",
    "    t_time = tree_values['POSITION_T'][tree_id] # tree_values\n",
    "    t_x = tree_values['POSITION_X'][tree_id]\n",
    "    t_y = tree_values['POSITION_Y'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "\n",
    "    t_brightness = {}\n",
    "    \n",
    "    if normalize:\n",
    "        base_brightness = []\n",
    "        for pic in pics:\n",
    "            base_brightness.append(cv2.sumElems(pic)[0] / float(pic.shape[0] * pic.shape[1]))\n",
    "\n",
    "    for br in t_tree:\n",
    "        brch = t_tree[br]\n",
    "        x = t_x[br]\n",
    "        y = t_y[br]\n",
    "        time = t_time[br]\n",
    "        brightness = []\n",
    "    \n",
    "        for i in range(len(brch)):\n",
    "            if synchronized or (not caspase):\n",
    "                if time[i] % 1800 == 0:\n",
    "                    pos = time[i] // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)     \n",
    "            else:\n",
    "                if ((time[i] - 76200) >= 0) & ((time[i] - 76200) % 1800 == 0):\n",
    "                    pos = (time[i] - 76200) // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)\n",
    "            \n",
    "        t_brightness[br] = brightness\n",
    "    return t_brightness, np.array(pics_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_brightness_template(tree_id, \n",
    "                                tree, \n",
    "                                tree_values, \n",
    "                                pics, \n",
    "                                diameter=DIAMETER, \n",
    "                                caspase=True, \n",
    "                                normalize=True,\n",
    "                                synchronized=False):\n",
    "    \"\"\"\n",
    "    Similar to extract_brightness(), except that it\n",
    "    takes video template form the user\n",
    "    \n",
    "    This function returns:\n",
    "    -   the brightness level of each spot in the tree, if such is measured.\n",
    "        The encoding follows that of the tree itself\n",
    "    -   cell death signal time-lapsed video of containing the cell belonging\n",
    "        to the 'tree_id'. Useful for debugging/sanity testing \n",
    "    \"\"\"\n",
    "    \n",
    "    pics_intersect = []\n",
    "\n",
    "    t_time = tree_values['POSITION_T'][tree_id] # tree_values\n",
    "    t_x = tree_values['POSITION_X'][tree_id]\n",
    "    t_y = tree_values['POSITION_Y'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "\n",
    "    t_brightness = {}\n",
    "    \n",
    "    if normalize:\n",
    "        base_brightness = []\n",
    "        for pic in pics:\n",
    "            base_brightness.append(cv2.sumElems(pic)[0] / float(pic.shape[0] * pic.shape[1]))\n",
    "\n",
    "    for br in t_tree:\n",
    "        brch = t_tree[br]\n",
    "        x = t_x[br]\n",
    "        y = t_y[br]\n",
    "        time = t_time[br]\n",
    "        brightness = []\n",
    "    \n",
    "        for i in range(len(brch)):\n",
    "            if synchronized or (not caspase):\n",
    "                if time[i] % 1800 == 0:\n",
    "                    pos = time[i] // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)\n",
    "            else:\n",
    "                if ((time[i] - 76200) >= 0) & ((time[i] - 76200) % 1800 == 0):\n",
    "                    pos = (time[i] - 76200) // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)\n",
    "            \n",
    "        t_brightness[br] = brightness\n",
    "    return t_brightness, np.array(pics_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_tree_to_contours(tree_values, contours):\n",
    "    \"\"\"\n",
    "    Given tree values and recognized contours, compute:\n",
    "    \n",
    "    -   'assocs': table listing recognized slit and the TREE_ID\n",
    "        of singly-placed cell tree located in the slit\n",
    "    -   'occupancy': list containing the number of cell trees\n",
    "        located in a slit. NOTE: the list is not associated with\n",
    "        ordering encoded in 'assocs'\n",
    "    \"\"\"\n",
    "\n",
    "    occuppancy = {x:0 for x in range(len(contours))}\n",
    "    cell_trees = []\n",
    "    slits = []\n",
    "\n",
    "    for tr in tree_values['POSITION_X'].keys():\n",
    "    \n",
    "        cell_trees.append(tr)\n",
    "\n",
    "        x = tree_values['POSITION_X'][tr][tr][0] / PIXEL_INCH_RATIO\n",
    "        y = tree_values['POSITION_Y'][tr][tr][0] / PIXEL_INCH_RATIO\n",
    "    \n",
    "        counter = 0\n",
    "        match = 0\n",
    "        matchloc = None\n",
    "    \n",
    "        for ct in cts:\n",
    "        \n",
    "            if cv2.pointPolygonTest(ct, (x, y), False) > 0:\n",
    "                occuppancy[counter] += 1\n",
    "                matchloc = counter\n",
    "                match += 1\n",
    "            counter +=  1\n",
    "        \n",
    "        if match == 0:\n",
    "            slits.append(None)\n",
    "        elif match == 1:\n",
    "            slits.append(matchloc)\n",
    "        else:\n",
    "            print(\"Tree %s got too many matches\" % tr)\n",
    "        \n",
    "    assocs = pd.DataFrame({'CELL_LINE': cell_trees, 'SLIT_ID': slits})\n",
    "    occuppancy = np.array(list(occuppancy.values()))\n",
    "    \n",
    "    return assocs, occuppancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_contour(contour_mask_path, min_size=7000, max_size=10000):\n",
    "    \"\"\"\n",
    "    Give contour mask picture (created by adjusting contrast/brightness\n",
    "    followed by RATS and \"fill holes\" command) detect contours of\n",
    "    slits annd return:\n",
    "    - the list of filtered contours\n",
    "    - the size list of filtered contours\n",
    "    - the size of all detected contours (for testing purpose)\n",
    "    \"\"\"\n",
    "    \n",
    "    ## collect contours and wrap into a function\n",
    "\n",
    "    im = cv2.imread(contour_mask_path)\n",
    "    gray= cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    im2, contours, hierarchy  = cv2.findContours(gray,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    all_cts_area = np.array([cv2.contourArea(x) for x  in contours])\n",
    "\n",
    "    filtered_cts = []\n",
    "    filtered_cts_area = []\n",
    "\n",
    "    for ct in contours:\n",
    "        ct_area = cv2.contourArea(ct)\n",
    "        if (ct_area <= max_size) and (ct_area >= min_size):\n",
    "            filtered_cts.append(ct)\n",
    "            filtered_cts_area.append(ct_area)\n",
    "            \n",
    "    return filtered_cts, filtered_cts_area, all_cts_area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTREE_ID:\\n    \"TREE\"\\n    \"BRANCH\"\\n    \"POSITION_T\"\\n    \"POSITION_X\"\\n    \"POSITION_Y\"\\n    \"CASPASE\"\\n    \"CASPASE_NORM\"\\n    \"CASPASE_SUB\"\\n    \"CASPASE_SUB_NORM\"\\n    \"PI\"\\n    \"PI_NORM\"\\n    \"PI_SUB\"\\n    \"PI_SUB_NORM\"\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TREE_ID:\n",
    "    \"TREE\"\n",
    "    \"BRANCH\"\n",
    "    \"POSITION_T\"\n",
    "    \"POSITION_X\"\n",
    "    \"POSITION_Y\"\n",
    "    \"CASPASE\"\n",
    "    \"CASPASE_NORM\"\n",
    "    \"CASPASE_SUB\"\n",
    "    \"CASPASE_SUB_NORM\"\n",
    "    \"PI\"\n",
    "    \"PI_NORM\"\n",
    "    \"PI_SUB\"\n",
    "    \"PI_SUB_NORM\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Unfiltered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "done = []\n",
    "dat = {}\n",
    "dat_f = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions = list(set(list(range(64))[1:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing position 01...\n",
      "  Reading files\n",
      "  Reading files done. Time elapsed: 0.370282\n",
      "  Parsing trees and values\n"
     ]
    }
   ],
   "source": [
    "diameter = 15\n",
    "\n",
    "for position in positions:\n",
    "    \n",
    "    if position < 10:\n",
    "        pos = \"0%d\" % position\n",
    "    else:\n",
    "        pos = str(position)\n",
    "    \n",
    "    if position not in done:\n",
    "\n",
    "\n",
    "        t = time.time()\n",
    "        print(\"Processing position %s...\\n  Reading files\" % pos)\n",
    "        \n",
    "        track_path = \"../test/eli-new-unsync-bf-%s/out-focus/merged/out/tracked/\" % pos\n",
    "        caspase_path = \"../test/eli-new-unsync-bf-%s/caspase/caspasexy%sc1.tif\" % (pos, pos)\n",
    "        caspase_sub_path = \"../test/eli-new-unsync-bf-%s/caspase/caspasexy%sc1_sub.tif\" % (pos, pos)\n",
    "        pi_path = \"../test/eli-new-unsync-bf-%s/pi/merged/merged.tif\" % pos\n",
    "        pi_sub_path = \"../test/eli-new-unsync-bf-%s/pi/merged/merged_sub.tif\" % pos\n",
    "\n",
    "        ba = pd.read_csv(os.path.join(track_path, 'Links in tracks statistics.csv'))\n",
    "        sits = pd.read_csv(os.path.join(track_path, 'Spots in tracks statistics.csv'))\n",
    "        print(\"  Reading files done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        ## parsing tree\n",
    "        t = time.time()\n",
    "        print(\"  Parsing trees and values\")\n",
    "        tree, branch, velocity, displacement = parse_trees(ba, parse_velocity_displacement=True)\n",
    "        svals = extract_values(tree, sits, ['POSITION_T', 'POSITION_X', 'POSITION_Y', 'TOTAL_INTENSITY', 'QUALITY'])\n",
    "        print(\"  Parsing done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        ## filter tree\n",
    "\n",
    "        t = time.time()\n",
    "        print(\"  Filtering tree\")\n",
    "        tree, branch, svals = filter_trees_by_time(tree, branch, svals)\n",
    "        print(\"  Filtering done. Time elapsed: %f\" % (time.time() - t))\n",
    "        \n",
    "        ## extract cell association\n",
    "        t = time.time()\n",
    "        print(\"  Getting contour\")\n",
    "        \n",
    "        path = \"../test/eli-new-unsync-bf-%s/in-focus/before\" % pos\n",
    "        impath = \"bf_in-focusxy%sc1c1-mask.tif\" % pos\n",
    "        \n",
    "        cts, _, _ = get_contour(os.path.join(path, impath))\n",
    "        assocs, _ = assign_tree_to_contours(svals, cts)\n",
    "        cell_trees = set(assocs.CELL_LINE[~assocs.SLIT_ID.isnull()].tolist())\n",
    "\n",
    "        print(\"  Contour recognition done. Time elapsed: %f\" % (time.time() - t))\n",
    "        ## extract cas + pi value\n",
    "\n",
    "        print(\"  Extarcting caspase and pi measurement values\")\n",
    "        t = time.time()\n",
    "        caspases = {}\n",
    "        caspases_norm = {}\n",
    "        caspases_sub = {}\n",
    "        caspases_sub_norm = {}\n",
    "        pis = {}\n",
    "        pis_norm = {}\n",
    "        pis_sub = {}\n",
    "        pis_sub_norm = {}\n",
    "    \n",
    "        pics_casp = get_video(caspase_path)\n",
    "        pics_casp_sub = get_video(caspase_sub_path)\n",
    "        pics_pi = get_video(pi_path)\n",
    "        pics_pi_sub = get_video(pi_sub_path)\n",
    "    \n",
    "        for k in tree.keys():\n",
    "\n",
    "            cs, _ = extract_brightness_template(k, \n",
    "                                                tree, \n",
    "                                                svals, \n",
    "                                                pics_casp, \n",
    "                                                caspase=True,\n",
    "                                                normalize=False,\n",
    "                                                synchronized=SYNCHRONIZED)\n",
    "            caspases[k] = cs\n",
    "    \n",
    "            csnorm, _ = extract_brightness_template(k, \n",
    "                                                    tree, \n",
    "                                                    svals, \n",
    "                                                    pics_casp, \n",
    "                                                    caspase=True, \n",
    "                                                    normalize=True, \n",
    "                                                    synchronized=SYNCHRONIZED)\n",
    "            caspases_norm[k] = csnorm\n",
    "    \n",
    "            cssub, _ = extract_brightness_template(k, \n",
    "                                                   tree, \n",
    "                                                   svals, \n",
    "                                                   pics_casp_sub, \n",
    "                                                   caspase=True,\n",
    "                                                   normalize=False,\n",
    "                                                   synchronized=SYNCHRONIZED)\n",
    "            caspases_sub[k] = cssub\n",
    "    \n",
    "            cssubnorm, _ = extract_brightness_template(k, \n",
    "                                                       tree, \n",
    "                                                       svals, \n",
    "                                                       pics_casp_sub, \n",
    "                                                       caspase=True, \n",
    "                                                       normalize=True, \n",
    "                                                       synchronized=SYNCHRONIZED)\n",
    "            caspases_sub_norm[k] = cssubnorm\n",
    "                \n",
    "    \n",
    "        print(\"  Extracting caspase done. Time elapsed: %f\" % (time.time() - t))\n",
    "    \n",
    "        t = time.time()\n",
    "        for k in tree.keys():\n",
    "    \n",
    "            pi, _ = extract_brightness_template(k, \n",
    "                                                tree, \n",
    "                                                svals, \n",
    "                                                pics_pi, \n",
    "                                                caspase=False, \n",
    "                                                normalize=False)\n",
    "            pis[k] = pi\n",
    "        \n",
    "            pinorm, _ = extract_brightness_template(k, \n",
    "                                                    tree, \n",
    "                                                    svals, \n",
    "                                                    pics_pi, \n",
    "                                                    caspase=False, \n",
    "                                                    normalize=True)\n",
    "            pis_norm[k] = pinorm\n",
    "        \n",
    "            pisub, _ = extract_brightness_template(k, \n",
    "                                                   tree, \n",
    "                                                   svals, \n",
    "                                                   pics_pi_sub, \n",
    "                                                   caspase=False, \n",
    "                                                   normalize=False)\n",
    "            pis_sub[k] = pisub\n",
    "        \n",
    "            pisubnorm, _ = extract_brightness_template(k, \n",
    "                                                       tree, \n",
    "                                                       svals, \n",
    "                                                       pics_pi_sub, \n",
    "                                                       caspase=False, \n",
    "                                                       normalize=True)\n",
    "            pis_sub_norm[k] = pisubnorm\n",
    "    \n",
    "        print(\"  Extracting pi done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        print(\"  Wrapping values\")\n",
    "        t = time.time()\n",
    "        \n",
    "        pos_dat = {}\n",
    "        pos_dat_f = {}\n",
    "        pos_dat_trees = {}\n",
    "        pos_dat_trees_f = {}\n",
    "        \n",
    "        for tr in tree.keys():\n",
    "            t_tree = {\n",
    "                \"TREE\": tree[tr],\n",
    "                \"BRANCH\": branch[tr],\n",
    "                \"POSITION_T\": svals[\"POSITION_T\"][tr],\n",
    "                \"POSITION_X\": svals[\"POSITION_X\"][tr],\n",
    "                \"POSITION_Y\": svals[\"POSITION_Y\"][tr],\n",
    "                \"CASPASE\": caspases[tr],\n",
    "                \"CASPASE_NORM\": caspases_norm[tr],\n",
    "                \"CASPASE_SUB\": caspases_sub[tr],\n",
    "                \"CASPASE_SUB_NORM\": caspases_sub_norm[tr],\n",
    "                \"PI\": pis[tr],\n",
    "                \"PI_NORM\": pis_norm[tr],\n",
    "                \"PI_SUB\": pis_sub[tr],\n",
    "                \"PI_SUB_NORM\": pis_sub_norm[tr],\n",
    "                \"VELOCITY\": velocity[tr],\n",
    "                \"DISPLACEMENT\": displacement[tr]\n",
    "            }\n",
    "            if tr in cell_trees:\n",
    "                pos_dat_trees_f[tr] = t_tree\n",
    "                pos_dat_trees[tr] = t_tree\n",
    "            else:\n",
    "                pos_dat_trees[tr] = t_tree\n",
    "    \n",
    "        pos_dat[\"TREES\"] = pos_dat_trees\n",
    "        pos_dat[\"GAP_PER_FRAME_SECONDS\"] = 600\n",
    "        pos_dat[\"PIXEL_TO_INCH\"] = 1 / .647\n",
    "        dat[pos] = pos_dat\n",
    "        \n",
    "        pos_dat_f[\"TREES\"] = pos_dat_trees_f\n",
    "        pos_dat_f[\"GAP_PER_FRAME_SECONDS\"] = 600\n",
    "        pos_dat_f[\"PIXEL_TO_INCH\"] = 1 / .647\n",
    "        dat_f[pos] = pos_dat_f\n",
    "        \n",
    "        done.append(position)\n",
    "        \n",
    "        for tree_id in cell_trees:    \n",
    "            dat_f[pos][\"TREES\"][tree_id][\"SLIT_ID\"] = int(assocs[assocs.CELL_LINE == tree_id][\"SLIT_ID\"].values[0])\n",
    "\n",
    "        print(\"  Extraction done. Time elapsed: %f\" % (time.time() - t))\n",
    "    else:\n",
    "        print(\"  Position %s already extracted\" % pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making data JSON compliant and export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_c = copy.deepcopy(dat)\n",
    "dat_fc = copy.deepcopy(dat_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Making dat JSON compliant\")\n",
    "for pos in dat_c.keys():\n",
    "    t = time.time()\n",
    "    print(\"  Doing position %s\" % pos)\n",
    "\n",
    "    for tid in dat_c[pos]['TREES'].keys():\n",
    "    ## change value of single tree\n",
    "        dat_c[pos]['TREES'][tid]['BRANCH'] = {str(k):(int(v[0]), int(v[1])) for k,v in dat_c[pos]['TREES'][tid]['BRANCH'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['TREE'] = {str(k):[int(val) for val in v] for k,v in dat_c[pos]['TREES'][tid]['TREE'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['POSITION_T'] = {str(k):[int(val) for val in v] for k,v in dat_c[pos]['TREES'][tid]['POSITION_T'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['POSITION_X'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['POSITION_X'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['POSITION_Y'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['POSITION_Y'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['CASPASE'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['CASPASE'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['CASPASE_NORM'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['CASPASE_NORM'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['CASPASE_SUB'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['CASPASE_SUB'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['CASPASE_SUB_NORM'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['CASPASE_SUB_NORM'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['PI'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['PI'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['PI_NORM'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['PI_NORM'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['PI_SUB'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['PI_SUB'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['PI_SUB_NORM'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['PI_SUB_NORM'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['VELOCITY'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['VELOCITY'].items()}\n",
    "        dat_c[pos]['TREES'][tid]['DISPLACEMENT'] = {str(k):v for k,v in dat_c[pos]['TREES'][tid]['DISPLACEMENT'].items()}\n",
    "\n",
    "    ## change value of trees\n",
    "    dat_c[pos]['TREES'] = {str(k):v for k,v in dat_c[pos]['TREES'].items()}\n",
    "    \n",
    "    print(\"  Finished. Time: %f\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Making dat JSON compliant\")\n",
    "for pos in dat_fc.keys():\n",
    "    t = time.time()\n",
    "    print(\"  Doing position %s\" % pos)\n",
    "\n",
    "    for tid in dat_fc[pos]['TREES'].keys():\n",
    "    ## change value of single tree\n",
    "        dat_fc[pos]['TREES'][tid]['BRANCH'] = {str(k):(int(v[0]), int(v[1])) for k,v in dat_fc[pos]['TREES'][tid]['BRANCH'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['TREE'] = {str(k):[int(val) for val in v] for k,v in dat_fc[pos]['TREES'][tid]['TREE'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['POSITION_T'] = {str(k):[int(val) for val in v] for k,v in dat_fc[pos]['TREES'][tid]['POSITION_T'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['POSITION_X'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['POSITION_X'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['POSITION_Y'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['POSITION_Y'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['CASPASE'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['CASPASE'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['CASPASE_NORM'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['CASPASE_NORM'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['CASPASE_SUB'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['CASPASE_SUB'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['CASPASE_SUB_NORM'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['CASPASE_SUB_NORM'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['PI'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['PI'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['PI_NORM'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['PI_NORM'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['PI_SUB'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['PI_SUB'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['PI_SUB_NORM'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['PI_SUB_NORM'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['VELOCITY'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['VELOCITY'].items()}\n",
    "        dat_fc[pos]['TREES'][tid]['DISPLACEMENT'] = {str(k):v for k,v in dat_fc[pos]['TREES'][tid]['DISPLACEMENT'].items()}\n",
    "\n",
    "    ## change value of trees\n",
    "    dat_fc[pos]['TREES'] = {str(k):v for k,v in dat_fc[pos]['TREES'].items()}\n",
    "    \n",
    "    print(\"  Finished. Time: %f\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../results/unsyn-filtered.json', 'w') as fp:\n",
    "    json.dump(dat_fc, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dat_fc, open(\"../results/unsyn-filtered.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../results/unsyn-unfiltered.json', 'w') as fp:\n",
    "    json.dump(dat_c, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dat_c, open(\"../results/unsyn-unfiltered.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making singly-placed cell data JSON compliant and export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_fdbt = pickle.load(open(\"../results/filtered_data_divided_before_treatment.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_fdbtdat = pickle.load(open(\"../results/filtered_data_divided_before_treatment_deaths_after_treatment.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_fdpis = pickle.load(open(\"../results/filtered_data_pi_sub.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dat JSON compliant\n",
      "  Doing position 26\n",
      "  Finished. Time: 0.002506\n",
      "  Doing position 45\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 46\n",
      "  Finished. Time: 0.003450\n",
      "  Doing position 43\n",
      "  Finished. Time: 0.003007\n",
      "  Doing position 22\n",
      "  Finished. Time: 0.004011\n",
      "  Doing position 28\n",
      "  Finished. Time: 0.004012\n",
      "  Doing position 58\n",
      "  Finished. Time: 0.002005\n",
      "  Doing position 63\n",
      "  Finished. Time: 0.005013\n",
      "  Doing position 52\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 50\n",
      "  Finished. Time: 0.001004\n",
      "  Doing position 51\n",
      "  Finished. Time: 0.002004\n",
      "  Doing position 59\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 27\n",
      "  Finished. Time: 0.008022\n",
      "  Doing position 15\n",
      "  Finished. Time: 0.004012\n",
      "  Doing position 14\n",
      "  Finished. Time: 0.003007\n",
      "  Doing position 09\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 31\n",
      "  Finished. Time: 0.004009\n",
      "  Doing position 24\n",
      "  Finished. Time: 0.002007\n",
      "  Doing position 25\n",
      "  Finished. Time: 0.005012\n",
      "  Doing position 10\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 35\n",
      "  Finished. Time: 0.001002\n",
      "  Doing position 32\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 17\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 21\n",
      "  Finished. Time: 0.004011\n",
      "  Doing position 18\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 30\n",
      "  Finished. Time: 0.003009\n",
      "  Doing position 56\n",
      "  Finished. Time: 0.001002\n",
      "  Doing position 49\n",
      "  Finished. Time: 0.004011\n",
      "  Doing position 08\n",
      "  Finished. Time: 0.003008\n",
      "  Doing position 41\n",
      "  Finished. Time: 0.002005\n",
      "  Doing position 57\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 48\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 42\n",
      "  Finished. Time: 0.002005\n",
      "  Doing position 33\n",
      "  Finished. Time: 0.002005\n",
      "  Doing position 02\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 39\n",
      "  Finished. Time: 0.002005\n",
      "  Doing position 06\n",
      "  Finished. Time: 0.002042\n",
      "  Doing position 47\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 36\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 62\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 29\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 03\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 34\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 40\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 12\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 55\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 01\n",
      "  Finished. Time: 0.016135\n",
      "  Doing position 61\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 07\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 16\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 23\n",
      "  Finished. Time: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Making dat JSON compliant\")\n",
    "for pos in dat_fdbt.keys():\n",
    "    t = time.time()\n",
    "    print(\"  Doing position %s\" % pos)\n",
    "\n",
    "    for tid in dat_fdbt[pos]['TREES'].keys():\n",
    "    ## change value of single tree\n",
    "        dat_fdbt[pos]['TREES'][tid]['BRANCH'] = {str(k):(int(v[0]), int(v[1])) for k,v in dat_fdbt[pos]['TREES'][tid]['BRANCH'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['TREE'] = {str(k):[int(val) for val in v] for k,v in dat_fdbt[pos]['TREES'][tid]['TREE'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['POSITION_T'] = {str(k):[int(val) for val in v] for k,v in dat_fdbt[pos]['TREES'][tid]['POSITION_T'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['POSITION_X'] = {str(k):v for k,v in dat_fdbt[pos]['TREES'][tid]['POSITION_X'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['POSITION_Y'] = {str(k):v for k,v in dat_fdbt[pos]['TREES'][tid]['POSITION_Y'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['CASPASE'] = {str(k):np.array(v).tolist() for k,v in dat_fdbt[pos]['TREES'][tid]['CASPASE'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['CASPASE_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdbt[pos]['TREES'][tid]['CASPASE_NORM'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['CASPASE_SUB'] = {str(k):np.array(v).tolist() for k,v in dat_fdbt[pos]['TREES'][tid]['CASPASE_SUB'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['CASPASE_SUB_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdbt[pos]['TREES'][tid]['CASPASE_SUB_NORM'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['PI'] = {str(k):np.array(v).tolist() for k,v in dat_fdbt[pos]['TREES'][tid]['PI'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['PI_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdbt[pos]['TREES'][tid]['PI_NORM'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['PI_SUB'] = {str(k):np.array(v).tolist() for k,v in dat_fdbt[pos]['TREES'][tid]['PI_SUB'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['PI_SUB_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdbt[pos]['TREES'][tid]['PI_SUB_NORM'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['VELOCITY'] = {str(k):v for k,v in dat_fdbt[pos]['TREES'][tid]['VELOCITY'].items()}\n",
    "        dat_fdbt[pos]['TREES'][tid]['DISPLACEMENT'] = {str(k):v for k,v in dat_fdbt[pos]['TREES'][tid]['DISPLACEMENT'].items()}\n",
    "\n",
    "    ## change value of trees\n",
    "    dat_fdbt[pos]['TREES'] = {str(k):v for k,v in dat_fdbt[pos]['TREES'].items()}\n",
    "    \n",
    "    print(\"  Finished. Time: %f\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dat JSON compliant\n",
      "  Doing position 26\n",
      "  Finished. Time: 0.002005\n",
      "  Doing position 45\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 46\n",
      "  Finished. Time: 0.003044\n",
      "  Doing position 43\n",
      "  Finished. Time: 0.000499\n",
      "  Doing position 22\n",
      "  Finished. Time: 0.001976\n",
      "  Doing position 28\n",
      "  Finished. Time: 0.003508\n",
      "  Doing position 58\n",
      "  Finished. Time: 0.001504\n",
      "  Doing position 36\n",
      "  Finished. Time: 0.000502\n",
      "  Doing position 52\n",
      "  Finished. Time: 0.000501\n",
      "  Doing position 50\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 51\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 59\n",
      "  Finished. Time: 0.000501\n",
      "  Doing position 27\n",
      "  Finished. Time: 0.006520\n",
      "  Doing position 15\n",
      "  Finished. Time: 0.004011\n",
      "  Doing position 14\n",
      "  Finished. Time: 0.004011\n",
      "  Doing position 61\n",
      "  Finished. Time: 0.007019\n",
      "  Doing position 09\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 31\n",
      "  Finished. Time: 0.003007\n",
      "  Doing position 25\n",
      "  Finished. Time: 0.004011\n",
      "  Doing position 10\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 35\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 32\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 17\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 21\n",
      "  Finished. Time: 0.003007\n",
      "  Doing position 18\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 30\n",
      "  Finished. Time: 0.002005\n",
      "  Doing position 56\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 49\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 08\n",
      "  Finished. Time: 0.002006\n",
      "  Doing position 41\n",
      "  Finished. Time: 0.002005\n",
      "  Doing position 57\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 48\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 42\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 33\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 02\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 39\n",
      "  Finished. Time: 0.001003\n",
      "  Doing position 06\n",
      "  Finished. Time: 0.002005\n",
      "  Doing position 47\n",
      "  Finished. Time: 0.001002\n",
      "  Doing position 63\n",
      "  Finished. Time: 0.002006\n",
      "  Doing position 62\n",
      "  Finished. Time: 0.003956\n",
      "  Doing position 29\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 03\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 34\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 40\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 12\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 55\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 01\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 24\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 07\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 16\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 23\n",
      "  Finished. Time: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Making dat JSON compliant\")\n",
    "for pos in dat_fdbtdat.keys():\n",
    "    t = time.time()\n",
    "    print(\"  Doing position %s\" % pos)\n",
    "\n",
    "    for tid in dat_fdbtdat[pos]['TREES'].keys():\n",
    "    ## change value of single tree\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['BRANCH'] = {str(k):(int(v[0]), int(v[1])) for k,v in dat_fdbtdat[pos]['TREES'][tid]['BRANCH'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['TREE'] = {str(k):[int(val) for val in v] for k,v in dat_fdbtdat[pos]['TREES'][tid]['TREE'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['POSITION_T'] = {str(k):[int(val) for val in v] for k,v in dat_fdbtdat[pos]['TREES'][tid]['POSITION_T'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['POSITION_X'] = {str(k):v for k,v in dat_fdbtdat[pos]['TREES'][tid]['POSITION_X'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['POSITION_Y'] = {str(k):v for k,v in dat_fdbtdat[pos]['TREES'][tid]['POSITION_Y'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['CASPASE'] = {str(k):np.array(v).tolist() for k,v in dat_fdbtdat[pos]['TREES'][tid]['CASPASE'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['CASPASE_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdbtdat[pos]['TREES'][tid]['CASPASE_NORM'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['CASPASE_SUB'] = {str(k):np.array(v).tolist() for k,v in dat_fdbtdat[pos]['TREES'][tid]['CASPASE_SUB'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['CASPASE_SUB_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdbtdat[pos]['TREES'][tid]['CASPASE_SUB_NORM'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['PI'] = {str(k):np.array(v).tolist() for k,v in dat_fdbtdat[pos]['TREES'][tid]['PI'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['PI_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdbtdat[pos]['TREES'][tid]['PI_NORM'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['PI_SUB'] = {str(k):np.array(v).tolist() for k,v in dat_fdbtdat[pos]['TREES'][tid]['PI_SUB'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['PI_SUB_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdbtdat[pos]['TREES'][tid]['PI_SUB_NORM'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['VELOCITY'] = {str(k):v for k,v in dat_fdbtdat[pos]['TREES'][tid]['VELOCITY'].items()}\n",
    "        dat_fdbtdat[pos]['TREES'][tid]['DISPLACEMENT'] = {str(k):v for k,v in dat_fdbtdat[pos]['TREES'][tid]['DISPLACEMENT'].items()}\n",
    "\n",
    "    ## change value of trees\n",
    "    dat_fdbtdat[pos]['TREES'] = {str(k):v for k,v in dat_fdbtdat[pos]['TREES'].items()}\n",
    "    \n",
    "    print(\"  Finished. Time: %f\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dat JSON compliant\n",
      "  Doing position 26\n",
      "  Finished. Time: 0.006046\n",
      "  Doing position 45\n",
      "  Finished. Time: 0.002510\n",
      "  Doing position 46\n",
      "  Finished. Time: 0.001506\n",
      "  Doing position 43\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 22\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 28\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 58\n",
      "  Finished. Time: 0.015671\n",
      "  Doing position 63\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 52\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 50\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 51\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 59\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 27\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 15\n",
      "  Finished. Time: 0.015614\n",
      "  Doing position 14\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 09\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 31\n",
      "  Finished. Time: 0.015637\n",
      "  Doing position 24\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 25\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 10\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 35\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 32\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 17\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 21\n",
      "  Finished. Time: 0.015621\n",
      "  Doing position 18\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 30\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 56\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 49\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 08\n",
      "  Finished. Time: 0.015598\n",
      "  Doing position 41\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 57\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 48\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 42\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 33\n",
      "  Finished. Time: 0.017140\n",
      "  Doing position 02\n",
      "  Finished. Time: 0.004972\n",
      "  Doing position 39\n",
      "  Finished. Time: 0.003038\n",
      "  Doing position 06\n",
      "  Finished. Time: 0.006016\n",
      "  Doing position 47\n",
      "  Finished. Time: 0.004011\n",
      "  Doing position 36\n",
      "  Finished. Time: 0.001007\n",
      "  Doing position 62\n",
      "  Finished. Time: 0.006011\n",
      "  Doing position 29\n",
      "  Finished. Time: 0.003009\n",
      "  Doing position 03\n",
      "  Finished. Time: 0.004011\n",
      "  Doing position 34\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 40\n",
      "  Finished. Time: 0.002006\n",
      "  Doing position 12\n",
      "  Finished. Time: 0.003153\n",
      "  Doing position 55\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 01\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 61\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 07\n",
      "  Finished. Time: 0.015665\n",
      "  Doing position 16\n",
      "  Finished. Time: 0.000000\n",
      "  Doing position 23\n",
      "  Finished. Time: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Making dat JSON compliant\")\n",
    "for pos in dat_fdpis.keys():\n",
    "    t = time.time()\n",
    "    print(\"  Doing position %s\" % pos)\n",
    "\n",
    "    for tid in dat_fdpis[pos]['TREES'].keys():\n",
    "    ## change value of single tree\n",
    "        dat_fdpis[pos]['TREES'][tid]['BRANCH'] = {str(k):(int(v[0]), int(v[1])) for k,v in dat_fdpis[pos]['TREES'][tid]['BRANCH'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['TREE'] = {str(k):[int(val) for val in v] for k,v in dat_fdpis[pos]['TREES'][tid]['TREE'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['POSITION_T'] = {str(k):[int(val) for val in v] for k,v in dat_fdpis[pos]['TREES'][tid]['POSITION_T'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['POSITION_X'] = {str(k):v for k,v in dat_fdpis[pos]['TREES'][tid]['POSITION_X'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['POSITION_Y'] = {str(k):v for k,v in dat_fdpis[pos]['TREES'][tid]['POSITION_Y'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['CASPASE'] = {str(k):np.array(v).tolist() for k,v in dat_fdpis[pos]['TREES'][tid]['CASPASE'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['CASPASE_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdpis[pos]['TREES'][tid]['CASPASE_NORM'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['CASPASE_SUB'] = {str(k):np.array(v).tolist() for k,v in dat_fdpis[pos]['TREES'][tid]['CASPASE_SUB'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['CASPASE_SUB_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdpis[pos]['TREES'][tid]['CASPASE_SUB_NORM'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['PI'] = {str(k):np.array(v).tolist() for k,v in dat_fdpis[pos]['TREES'][tid]['PI'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['PI_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdpis[pos]['TREES'][tid]['PI_NORM'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['PI_SUB'] = {str(k):np.array(v).tolist() for k,v in dat_fdpis[pos]['TREES'][tid]['PI_SUB'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['PI_SUB_NORM'] = {str(k):np.array(v).tolist() for k,v in dat_fdpis[pos]['TREES'][tid]['PI_SUB_NORM'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['VELOCITY'] = {str(k):v for k,v in dat_fdpis[pos]['TREES'][tid]['VELOCITY'].items()}\n",
    "        dat_fdpis[pos]['TREES'][tid]['DISPLACEMENT'] = {str(k):v for k,v in dat_fdpis[pos]['TREES'][tid]['DISPLACEMENT'].items()}\n",
    "\n",
    "    ## change value of trees\n",
    "    dat_fdpis[pos]['TREES'] = {str(k):v for k,v in dat_fdpis[pos]['TREES'].items()}\n",
    "    \n",
    "    dat_fdpis['01']['PIXEL_TO_INCH'] = 1\n",
    "    \n",
    "    print(\"  Finished. Time: %f\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../results/unsyn-single-div-before-treatment.json', 'w') as fp:\n",
    "    json.dump(dat_fdbt, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../results/unsyn-single-div-before-treatment-death-after-treatment.json', 'w') as fp:\n",
    "    json.dump(dat_fdbtdat, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../results/unsyn-sub-pi-filtered.json', 'w') as fp:\n",
    "    json.dump(dat_fdpis, fp)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
