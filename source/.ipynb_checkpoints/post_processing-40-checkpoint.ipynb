{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-af226334539a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'presentation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from sys import getsizeof\n",
    "\n",
    "import cv2\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiffcapture as tc\n",
    "\n",
    "from tifffile import imsave\n",
    "from matplotlib import pyplot as pt\n",
    "\n",
    "pt.style.use('presentation')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSITION = 40\n",
    "TIME_UNIT_FACTOR = 600\n",
    "PIXEL_INCH_RATIO = .647\n",
    "DIAMETER = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to exit data\n",
    "exit_dat = '../results/40-47.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track_path = '../test/eli-new-unsync-bf-%d/out-focus/merged/out/tracked/' % POSITION\n",
    "with open(os.path.join(track_path, 'merged_Tracks.xml')) as fd:\n",
    "    td = xmltodict.parse(fd.read())\n",
    "    \n",
    "with open(os.path.join(track_path, 'merged.xml')) as fd:\n",
    "    sd = xmltodict.parse(fd.read())\n",
    "    \n",
    "ss = pd.read_csv(os.path.join(track_path, 'All Spots statistics.csv'))\n",
    "ts = pd.read_csv(os.path.join(track_path, 'Track statistics.csv'))\n",
    "ba = pd.read_csv(os.path.join(track_path, 'Links in tracks statistics.csv'))\n",
    "sits = pd.read_csv(os.path.join(track_path, 'Spots in tracks statistics.csv'))\n",
    "\n",
    "## TODO: include the last one file (branch statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caspase_path = \"../test/eli-new-unsync-bf-%d/caspase/\" % POSITION\n",
    "caspase_tiff_path = os.path.join(caspase_path, \"caspasexy%dc1_sub.tif\" % POSITION)\n",
    "# tiff_path_intersection = os.path.join(caspase_path, \"caspasexy%dc1_inter.tif\" % POSITION)\n",
    "\n",
    "out_path_pics = \"../results/pics/unsyn/\"\n",
    "if not os.path.exists(out_path_pics):\n",
    "    os.makedirs(out_path_pics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Function Defs and Uses\n",
    "\n",
    "### Reference-safe key removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removekey(d, key):\n",
    "    \"\"\"\n",
    "    Remove a key from a  dictionary without destroying the reference\n",
    "    to removed object (which might be used by other processes)\n",
    "    \"\"\"\n",
    "    if key in d:\n",
    "        r = dict(d)\n",
    "        del r[key]\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct tree from \"Links in Track Statistics\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_trees(links_tab):\n",
    "    \"\"\"\n",
    "    Given 'links in tab statistics' from TrackMate.\n",
    "    Construct data structures representing trees ('tree') and\n",
    "    their branching ('branch') respectively.\n",
    "    \n",
    "    -   'tree' contains mapping of TREE_ID (which is the same as\n",
    "        the id of root's SPOT_ID) to its associated tree.\n",
    "        Each tree is in turn a map of TREE_BRANCH_ID\n",
    "        (which is the branch's first spot's SPOT_ID)\n",
    "        to its branch which is represented as list of SPOT_ID's.\n",
    "    -   'branch' encodes how the tree is structured. It contains\n",
    "        mapping of TREE_ID to the branching configuration.\n",
    "        The branching configuration is encoded as mapping of\n",
    "        BRANCH_ID to its two children's BRANCH_ID.\n",
    "    \"\"\"\n",
    "    \n",
    "    tree = {}\n",
    "    branch = {}\n",
    "    for track in links_tab.TRACK_ID.unique():\n",
    "    \n",
    "        sub = links_tab[links_tab.TRACK_ID == track]\n",
    "\n",
    "        this_lines = {}\n",
    "        this_branches = {}\n",
    "        stack = []\n",
    "    \n",
    "        groot = sub.iloc[0][3] \n",
    "        print(\"Parsing tree %s\" % groot)\n",
    "        stack.append(groot)\n",
    "    \n",
    "        while len(stack) > 0:\n",
    "        \n",
    "            root = stack.pop()\n",
    "            track = [root]\n",
    "            print(\"Parsing subtree %s\" % root)\n",
    "            nsub = sub[sub.SPOT_SOURCE_ID == root]\n",
    "        \n",
    "            while nsub.index.size > 0:\n",
    "                if nsub.index.size == 1:\n",
    "                    this = nsub.iloc[0][4]\n",
    "                    track.append(this)\n",
    "                    nsub = sub[sub.SPOT_SOURCE_ID == this]\n",
    "                else:\n",
    "                    stack.append(nsub.iloc[0][4])\n",
    "                    stack.append(nsub.iloc[1][4])\n",
    "                    this_branches[root] = (nsub.iloc[0][4], nsub.iloc[1][4])\n",
    "                    print(\"breaking\")\n",
    "                    break\n",
    "                \n",
    "            this_lines[root] = track\n",
    "            print(\"adding branch %s\" % root)\n",
    "    \n",
    "        print(\"Finishing...\")\n",
    "        tree[groot] = this_lines\n",
    "        branch[groot] = this_branches\n",
    "        \n",
    "    return tree, branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract values measured by TrackMate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_values(tree, spots_tab, colnames):\n",
    "    \"\"\"\n",
    "    Extract varoius measurement values from spots statistics and save it\n",
    "    in format similar to parsed tree. The list of values to be extracted\n",
    "    from spots statistics is defined in 'colnames' \n",
    "    \n",
    "    The information will be stored in following format:\n",
    "    map(TYPE:(TREE_ID:TREE_BRANCH:list(VALUES))\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    vals = {}\n",
    "\n",
    "    for tr in tree:\n",
    "    \n",
    "        print(\"extracting values for %s\" % tr)\n",
    "    \n",
    "        for colname in colnames:\n",
    "        \n",
    "            val_tree = {}\n",
    "        \n",
    "            for br in tree[tr]:\n",
    "            \n",
    "                brkeys = tree[tr][br]\n",
    "                brvals = [sits[sits.ID == x][colname].values[0] for x in brkeys]\n",
    "            \n",
    "                val_tree[br] = brvals\n",
    "            \n",
    "            if colname not in vals:\n",
    "                vals[colname] = {}\n",
    "            \n",
    "            vals[colname][tr] = val_tree\n",
    "            \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot tree values for a given tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_tree_value(tree_id, value, tree_values):\n",
    "    \"\"\"\n",
    "    Plot a given value of a given tree over the time\n",
    "    \"\"\"\n",
    "    \n",
    "    for key in tree_values['POSITION_T'][tree_id]:\n",
    "    \n",
    "        pt.plot(tree_values['POSITION_T'][tree_id][key], \n",
    "                svals['TOTAL_INTENSITY'][tree_id][key], \n",
    "                label=\"%d\" % key)\n",
    "    \n",
    "    pt.title(\"%s of tree %d over time\" % (value, tree_id))\n",
    "    pt.xlabel(\"Time\")\n",
    "    pt.ylabel(\"%s\" % value)\n",
    "    frame = pt.gcf()\n",
    "    frame.set_size_inches(20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognize slits in contour mask picture (simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recognize_slits(img, minsize=6000, maxsize=float(\"inf\")):\n",
    "    \"\"\"\n",
    "    Reads contour mask picture and recognizes slits.\n",
    "    Slit is defined as having size between $minsize and $maxsize\n",
    "    This is a simplified version of get_contour\n",
    "    \"\"\"\n",
    "    gray= cv2.cvtColor(img,\n",
    "                       cv2.COLOR_BGR2GRAY)\n",
    "    im2, contours, hierarchy  = cv2.findContours(gray, \n",
    "                                                 cv2.RETR_LIST,\n",
    "                                                 cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cts = [ct for ct in contours if (cv2.contourArea(ct) > minsize and cv2.contourArea(ct) < maxsize)]\n",
    "    return cts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract slits, their corresponding area and the area of all contours (slits or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_contour(contour_mask_path, min_size=7000, max_size=10000):\n",
    "    \"\"\"\n",
    "    Give contour mask picture (created by adjusting contrast/brightness\n",
    "    followed by RATS and \"fill holes\" command) detect contours of\n",
    "    slits annd return:\n",
    "    - the list of filtered contours\n",
    "    - the size list of filtered contours\n",
    "    - the size of all detected contours (for testing purpose)\n",
    "    \"\"\"\n",
    "    \n",
    "    ## collect contours and wrap into a function\n",
    "\n",
    "    im = cv2.imread(contour_mask_path)\n",
    "    gray= cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    im2, contours, hierarchy  = cv2.findContours(gray,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    all_cts_area = np.array([cv2.contourArea(x) for x  in contours])\n",
    "\n",
    "    filtered_cts = []\n",
    "    filtered_cts_area = []\n",
    "\n",
    "    for ct in contours:\n",
    "        ct_area = cv2.contourArea(ct)\n",
    "        if (ct_area <= max_size) and (ct_area >= min_size):\n",
    "            filtered_cts.append(ct)\n",
    "            filtered_cts_area.append(ct_area)\n",
    "            \n",
    "    return filtered_cts, filtered_cts_area, all_cts_area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Assign cell tree to a contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_tree_to_contours(tree_values, contours):\n",
    "    \"\"\"\n",
    "    Given tree values and recognized contours, compute:\n",
    "    \n",
    "    -   'assocs': table listing recognized slit and the TREE_ID\n",
    "        of singly-placed cell tree located in the slit\n",
    "    -   'occupancy': list containing the number of cell trees\n",
    "        located in a slit. NOTE: the list is not associated with\n",
    "        ordering encoded in 'assocs'\n",
    "    \"\"\"\n",
    "\n",
    "    occuppancy = {x:0 for x in range(len(contours))}\n",
    "    cell_trees = []\n",
    "    slits = []\n",
    "\n",
    "    for tr in tree_values['POSITION_X'].keys():\n",
    "    \n",
    "        cell_trees.append(tr)\n",
    "\n",
    "        x = tree_values['POSITION_X'][tr][tr][0] / PIXEL_INCH_RATIO\n",
    "        y = tree_values['POSITION_Y'][tr][tr][0] / PIXEL_INCH_RATIO\n",
    "    \n",
    "        counter = 0\n",
    "        match = 0\n",
    "        matchloc = None\n",
    "    \n",
    "        for ct in cts:\n",
    "        \n",
    "            if cv2.pointPolygonTest(ct, (x, y), False) > 0:\n",
    "                occuppancy[counter] += 1\n",
    "                matchloc = counter\n",
    "                match += 1\n",
    "            counter +=  1\n",
    "        \n",
    "        if match == 0:\n",
    "            slits.append(None)\n",
    "        elif match == 1:\n",
    "            slits.append(matchloc)\n",
    "        else:\n",
    "            print(\"Tree %s got too many matches\" % tr)\n",
    "        \n",
    "    assocs = pd.DataFrame({'CELL_LINE': cell_trees, 'SLIT_ID': slits})\n",
    "    occuppancy = np.array(list(occuppancy.values()))\n",
    "    \n",
    "    return assocs, occuppancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out trees laying outside the allowed time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_trees_by_time(tree, branch, tree_values, min_time=0, max_time=10):\n",
    "    \"\"\"\n",
    "    Filter out trees which measurement time start before or after\n",
    "    the time as defined in 'min_time' and 'max_time'.\n",
    "    \n",
    "    Measurement time is defined as the return value from TrackMate\n",
    "    encoded as 'POSITION_T'\n",
    "    \"\"\"\n",
    "    \n",
    "    tree_values_filtered = {}\n",
    "    tree = copy.deepcopy(tree)\n",
    "    branch = copy.deepcopy(branch)\n",
    "\n",
    "    for v in tree_values.keys():\n",
    "        tree_values_filtered[v] = {}\n",
    "\n",
    "    for key in tree_values['POSITION_T'].keys():\n",
    "    \n",
    "        if (tree_values['POSITION_T'][key][key][0] >= min_time) and (tree_values['POSITION_T'][key][key][0] <= max_time):\n",
    "            for k in tree_values_filtered.keys():\n",
    "                tree_values_filtered[k][key] = tree_values[k][key]\n",
    "        else:\n",
    "            tree = removekey(tree, key)\n",
    "            branch = removekey(branch, key)\n",
    "                \n",
    "    return  tree, branch, tree_values_filtered "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Computer tree's first division time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_first_division_time(tree_id, tree, branch, tree_measurements, mode=['avg', 'min', 'max']):\n",
    "    \"\"\"\n",
    "    Compute the first division time of a tree. The first division time\n",
    "    could be computed with following mode:\n",
    "    \n",
    "    -   'avg': averaging time difference between the last measurement\n",
    "        time of main branch and first measurement time of each \n",
    "        child branches\n",
    "    -   'min': taking the minimum of both values\n",
    "    -   'max': taking the maximum of both values\n",
    "    \"\"\"    \n",
    "    \n",
    "    t_time = tree_measurements['POSITION_T'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "    t_branch = branch[tree_id]\n",
    "    \n",
    "    div_end_main = t_time[tree_id][-1]\n",
    "    div_start_1 = t_time[t_branch[tree_id][0]][0]\n",
    "    div_start_2 = t_time[t_branch[tree_id][1]][0]\n",
    "    \n",
    "    if mode == 'avg':\n",
    "        return div_end_main + float(div_start_1 + div_start_2 - 2 * div_end_main) / 4\n",
    "    elif mode == 'min':\n",
    "        return div_end_main + min((div_start_2 - div_end_main) / 2, (div_start_2 - div_end_main) / 2)\n",
    "    elif mode == 'max':\n",
    "        return div_end_main + max((div_start_2 - div_end_main) / 2, (div_start_2 - div_end_main) / 2)\n",
    "    elif mode == ['avg', 'min', 'max']:\n",
    "        # default mode, compute avg\n",
    "        return div_end_main + float(div_start_1 + div_start_2 - 2 * div_end_main) / 4\n",
    "    else:\n",
    "        raise(\"Wrong mode. Mode has to be either 'avg', 'max' or 'min\")\n",
    "        \n",
    "\n",
    "def compute_first_division_time_list(tree_ids, tree, branch, tree_measurements, mode=['avg', 'min', 'max']):\n",
    "    \"\"\"\n",
    "    Wrapper function of compute_first_division_time().\n",
    "    This function takes list of TREE_IDs and compute \n",
    "    the first division time for each tree.\n",
    "    \"\"\"\n",
    "\n",
    "    div_times = []\n",
    "\n",
    "    for t in tree_ids:\n",
    "        div_times.append(compute_first_division_time(t, tree, branch, tree_measurements, mode=mode))\n",
    "    \n",
    "#         print(\"t1, t2, t3: %d, %d, %d\" % (div_end_main, div_start_1, div_start_2))\n",
    "#         print(\"t_div: %f\" % div_time)\n",
    "    \n",
    "    return div_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get trees by placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_trees_by_placement(tree_assoc, placement=1):\n",
    "    \"\"\"\n",
    "    Get all cell trees that have the same placement as described in argument.\n",
    "    A cell tree is of placement n if it is located in a slit with (n - 1)\n",
    "    other cell trees. 'placement' is by definition larger than 0\n",
    "    \"\"\"\n",
    "    if placement < 1:\n",
    "        print(\"'placement' has to be at least 1\")\n",
    "        return []\n",
    "    else:\n",
    "        trees = []\n",
    "        for slit in tree_assoc.SLIT_ID.unique():\n",
    "            if tree_assoc[tree_assoc.SLIT_ID == slit].index.size == placement:\n",
    "                trees.append(tree_assoc[tree_assoc.SLIT_ID == slit]['CELL_LINE'].values[0])\n",
    "    \n",
    "        return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Filter out invalid trees and create statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_invalid_trees(singly_placed_trees, tree, branch, tree_values):\n",
    "    \"\"\"\n",
    "    Iteratively filter out invalid trees.\n",
    "    \n",
    "    Strategy:\n",
    "\n",
    "    I.  For one division analysis\n",
    "        1. Find singly placed trees:\n",
    "        2. Do Cell Death Signal Filtering\n",
    "        3. Find tree with one division\n",
    "        4. Find tree with T(div) < t(treatment)\n",
    "        5. Find tree with T(death) > t(treatment)\n",
    "        \n",
    "    II. in the new implementation the cells with no division are also valid\n",
    "    \n",
    "    Collected statistics:\n",
    "    1. # singly-placed slits\n",
    "    2. # tree with zero div\n",
    "    3. # tree with one div\n",
    "    4. # tree with T(div) < t(treatment)\n",
    "    5. # tree with T(death) > t(treatment)\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate number of divs for each tree\n",
    "    singly_placed_tree_div = []\n",
    "    for t in singly_placed_tree:\n",
    "        ### return: tree-division\n",
    "        singly_placed_tree_div.append(len(tree_values['POSITION_T'][t].keys()))\n",
    "\n",
    "    ## filter out trees having other than one division\n",
    "    \n",
    "    # trees with one division event\n",
    "    ### return: no div tree\n",
    "    invalid_tree_nodiv = list(np.array(singly_placed_tree)[np.array(singly_placed_tree_div) == 1])\n",
    "    ### return: more one div tree\n",
    "    invalid_tree_morethan1div = list(np.array(singly_placed_tree)[np.array(singly_placed_tree_div) > 3])\n",
    "    ### return: one div tree\n",
    "    tree_one_div = list(np.array(singly_placed_tree)[np.array(singly_placed_tree_div) == 3])\n",
    "\n",
    "    print(\"# of singly-placed trees with 0 div: %d\" % len(invalid_tree_nodiv))\n",
    "    print(\"# of singly-placed trees with 1 div: %d\" % len(tree_one_div))\n",
    "    print(\"# of singly-placed trees with >1 divs: %d\" % len(invalid_tree_morethan1div))\n",
    "\n",
    "    ## compute div times\n",
    "    \n",
    "    ### return: division times of one div tree\n",
    "    tree_one_div_div_times = compute_first_division_time_list(tree_one_div, tree, branch, tree_values, mode='avg')\n",
    "\n",
    "    ## filter out trees with division after treatment\n",
    "\n",
    "    valid = np.array(tree_one_div_div_times) < (126 * TIME_UNIT_FACTOR)\n",
    "    \n",
    "    invalid_tree_divaftertreatment = list(np.array(tree_one_div)[~valid])\n",
    "    ### return: div before treatment tree\n",
    "    tree_divbfrtreatment = list(np.array(tree_one_div)[valid])\n",
    "    ### return: division times of div before treatment tree\n",
    "    tree_divbfrtreatment_div_times = list(np.array(tree_one_div_div_times)[valid])\n",
    "\n",
    "    print(\"# trees with division time before treatment: %d\" % len(tree_divbfrtreatment))\n",
    "    \n",
    "    ## filter out trees with child's death before treatment\n",
    "\n",
    "    # compute the death time of both child branches\n",
    "    death_times_1 = []\n",
    "    death_times_2 = []\n",
    "\n",
    "    for t in tree_divbfrtreatment:\n",
    "        t_time = svals['POSITION_T'][t]\n",
    "        t_tree = tree[t]\n",
    "        t_branch = branch[t]\n",
    "    \n",
    "        last_time_1 = t_time[t_branch[t][0]][-1]\n",
    "        last_time_2 = t_time[t_branch[t][1]][-1]\n",
    "    \n",
    "        death_times_1.append(last_time_1)\n",
    "        death_times_2.append(last_time_2)\n",
    "\n",
    "    valid1 = np.array(death_times_1) > (126 * TIME_UNIT_FACTOR)\n",
    "    valid2 = np.array(death_times_2) > (126 * TIME_UNIT_FACTOR)\n",
    "    valid = valid1 & valid2\n",
    "    \n",
    "    tree_divbfrtreatment_last_time_1 = death_times_1\n",
    "    tree_divbfrtreatment_last_time_2 = death_times_2\n",
    "\n",
    "    invalid_tree_deathbeforetreatment = list(np.array(tree_divbfrtreatment)[~valid])\n",
    "    ## return: death after treatment tree\n",
    "    tree_deathaftertreatment = list(np.array(tree_divbfrtreatment)[valid])\n",
    "    ## return: death time of 1st child\n",
    "    last_time_1 = list(np.array(death_times_1)[valid])\n",
    "    ## return: death time of 2nd child\n",
    "    last_time_2 = list(np.array(death_times_2)[valid])\n",
    "    ## return:  division times of death after treatment tree\n",
    "    tree_deathaftertreatment_div_times = list(np.array(tree_divbfrtreatment_div_times)[valid])\n",
    "    print(\"# trees with both branches' last measurement time after treatment: %d\" % len(tree_deathaftertreatment))\n",
    "    \n",
    "    return singly_placed_tree_div, \\\n",
    "            invalid_tree_nodiv, \\\n",
    "            invalid_tree_morethan1div, \\\n",
    "            tree_one_div, \\\n",
    "            tree_one_div_div_times, \\\n",
    "            tree_divbfrtreatment, \\\n",
    "            tree_divbfrtreatment_div_times, \\\n",
    "            tree_divbfrtreatment_last_time_1, \\\n",
    "            tree_divbfrtreatment_last_time_2, \\\n",
    "            tree_deathaftertreatment, \\\n",
    "            tree_deathaftertreatment_div_times, \\\n",
    "            last_time_1, \\\n",
    "            last_time_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct left-depth-first queue for a given (sub)tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_queue(br, q, cur):\n",
    "    \"\"\"\n",
    "    Given branching configuration of a tree,\n",
    "    construct queue representation (DFS) of such tree\n",
    "    \"\"\"\n",
    "    \n",
    "    if cur not in br:\n",
    "        q.append(cur)\n",
    "        return q\n",
    "    else:\n",
    "        q.append(cur)\n",
    "        q = construct_queue(br, q, br[cur][0])\n",
    "        q = construct_queue(br, q, br[cur][1])\n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and write video time-lapse for given tree in its associated slit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_snapshot(tree_ids, tree_assoc, slit_contours, tree, branch, tree_values, tiff_path, out_path):\n",
    "    \"\"\"\n",
    "    Create video containing trees, whic are STRICTLY assumed to be in one slit,\n",
    "    and write the video (as TIFF) on given path.\n",
    "    \n",
    "    Each spot in the tree will be annotated with green dot. The slit, which\n",
    "    trees reside in, will be highlighted in red line.\n",
    "    \n",
    "    Since the video only contains the slit in which the first tree resides in,\n",
    "    only trees located in the same slit as the first tree will be shown in the video.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### ALL tree_ids HAVE TO OCCUPY THE SAME SLIT\n",
    "    \n",
    "    print(\"Exporting snapshot for trees: %s\" % str(tree_ids))\n",
    "    \n",
    "    ### STEP I: parse TIFF template\n",
    "    \n",
    "    t_slit_id = int(tree_assoc[tree_assoc.CELL_LINE == tree_ids[0]].SLIT_ID.values[0])\n",
    "    t_slit = slit_contours[t_slit_id]\n",
    "    \n",
    "    ## import tiff images\n",
    "    tifmask = tc.opentiff(tiff_path)\n",
    "\n",
    "    ## first image\n",
    "    _, first_img = tifmask.retrieve()\n",
    "    first_img = cv2.cvtColor(first_img,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.drawContours(first_img, [t_slit], -1, (255, 0, 0), 4)\n",
    "\n",
    "    ## bounding box for slices\n",
    "    bb = cv2.boundingRect(t_slit)\n",
    "    bb = (bb[0], bb[1], bb[0] + bb[2], bb[1] + bb[3])\n",
    "    # extend bounding box by 10 pixels to all directions if possible\n",
    "    bb = (max(0, bb[0] - 10), \n",
    "          max(0, bb[1] - 10), \n",
    "          min(first_img.shape[0], bb[2] + 10),\n",
    "          min(first_img.shape[1], bb[3] + 10))\n",
    "\n",
    "    # assign bounding box for first image\n",
    "    cv2.rectangle(first_img, (bb[0], bb[1]), (bb[2], bb[3]), (0, 0, 255))\n",
    "\n",
    "    ## slices\n",
    "    pics = [first_img]\n",
    "\n",
    "    for slide in tifmask:\n",
    "        # convert grayscale to RGB\n",
    "        slide = cv2.cvtColor(slide, cv2.COLOR_GRAY2RGB)\n",
    "        # draw contour of slit\n",
    "        cv2.drawContours(slide, [t_slit], -1, (255, 0, 0), 4)\n",
    "        cv2.rectangle(slide, (bb[0], bb[1]), (bb[2], bb[3]), (0, 0, 255))\n",
    "        pics.append(slide)\n",
    "    \n",
    "    # free memory\n",
    "    tifmask.release()\n",
    "    \n",
    "    ### STEP II: assign track onto template\n",
    "    \n",
    "    for tree_id in tree_ids:\n",
    "        \n",
    "        print(\"Exporting snapshot for tree %d...\" % tree_id)\n",
    "    \n",
    "        t_slit_id = int(tree_assoc[tree_assoc.CELL_LINE == tree_id].SLIT_ID.values[0])\n",
    "        t_slit = slit_contours[t_slit_id]\n",
    "        t_tree = tree[tree_id]\n",
    "        t_branch = branch[tree_id]\n",
    "        t_time = tree_values['POSITION_T'][tree_id]\n",
    "        t_x = tree_values['POSITION_X'][tree_id]\n",
    "        t_y = tree_values['POSITION_Y'][tree_id]\n",
    "\n",
    "        ## extract spatial info and embed into image\n",
    "        t_queue = construct_queue(t_branch, [], tree_id)\n",
    "    \n",
    "        print(\"branch configuration for tree %d:\\n%s\" % (tree_id, str(t_branch)))\n",
    "        print(\"parsed queue for tree %d: %s\" % (tree_id, str(t_queue)))\n",
    "    \n",
    "        for br in t_queue:\n",
    "            t_tree_br = t_tree[br]\n",
    "    \n",
    "            # mark identified dots on corresponding slide\n",
    "            for i in range(len(t_tree_br)):\n",
    "                this_t = int(t_time[br][i] / TIME_UNIT_FACTOR)\n",
    "                this_x = t_x[br][i] / PIXEL_INCH_RATIO\n",
    "                this_y = t_y[br][i] / PIXEL_INCH_RATIO\n",
    "                img = pics[this_t]\n",
    "        \n",
    "                cv2.circle(img, (int(this_x), int(this_y)), 4, (0, 255, 0), -1)\n",
    "\n",
    "    ## crop images\n",
    "    pics_cropped = []\n",
    "    for i in range(len(pics)):\n",
    "        this_pic_cropped = pics[i][bb[1]:bb[3], bb[0]:bb[2]]\n",
    "        pics_cropped.append(this_pic_cropped)\n",
    "\n",
    "    ## write vid\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    print(\"writting video to dir: %s\" % out_path) \n",
    "    \n",
    "    ## save to multipages tiff\n",
    "    imsave(os.path.join(out_path, '%d.tiff' % t), np.array(pics_cropped))\n",
    "    \n",
    "    ## release memory\n",
    "    pics = []\n",
    "    pics_cropped = []\n",
    "    \n",
    "    print(\"#Trees snapshot exported\")\n",
    "    \n",
    "    \n",
    "def export_snapshot_slit(slit_id, tree_assoc, slit_contours, tree, branch, tree_values, tiff_path, out_path):\n",
    "    \"\"\"\n",
    "    Wrapper function for 'export_snapshot()'. In this function a user is only\n",
    "    required to give the ID of slit of interest. 'export_snapshot()' will then\n",
    "    be callld with trees residing in the passed slit.\n",
    "    \"\"\"\n",
    "    print(\"Exporting snapshot for slit %d\" % slit_id)\n",
    "    tree_ids = tree_assoc[tree_assoc.SLIT_ID == slit_id]['CELL_LINE'].tolist()\n",
    "    export_snapshot(tree_ids, \n",
    "                    tree_assoc, \n",
    "                    slit_contours, \n",
    "                    tree, \n",
    "                    branch, \n",
    "                    tree_values, \n",
    "                    tiff_path, \n",
    "                    out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read TIFF into list of frames (represented as multidim array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video(path, to_rgb=False):\n",
    "    \"\"\"\n",
    "    Read TIFF file containing multiple stacks (a video)\n",
    "    and return sequential array of frame encoded as\n",
    "    multidimensional array\n",
    "    \"\"\"\n",
    "    \n",
    "    tif = tc.opentiff(path)\n",
    "    \n",
    "    ## first image\n",
    "    _, first_img = tif.retrieve()\n",
    "    if to_rgb:\n",
    "        first_img = cv2.cvtColor(first_img,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    ## slices\n",
    "    pics = [first_img]\n",
    "\n",
    "    for slide in tif:\n",
    "        # convert grayscale to RGB\n",
    "        if to_rgb:\n",
    "            slide = cv2.cvtColor(slide, cv2.COLOR_GRAY2RGB)\n",
    "        pics.append(slide)\n",
    "    \n",
    "    return pics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract (procedded) cell death signal video's brightness level for each spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_brightness(tree_id, tree, tree_values, reference_vid_path, diameter=12):\n",
    "    \"\"\"\n",
    "    Given cell death signal video, extract brightness level for each position\n",
    "    of tracked cell trees, if such poisition coincides with the.\n",
    "    \n",
    "    This function returns:\n",
    "    -   the brightness level of each spot in the tree, if such is measured.\n",
    "        The encoding follows that of the tree itself\n",
    "    -   cell death signal time-lapsed video of containing the cell belonging\n",
    "        to the 'tree_id'. Useful for debugging/sanity testing \n",
    "    \"\"\"\n",
    "    \n",
    "    pics = get_video(reference_vid_path)\n",
    "    pics_intersect = []\n",
    "\n",
    "    t_time = tree_values['POSITION_T'][tree_id] # tree_values\n",
    "    t_x = tree_values['POSITION_X'][tree_id]\n",
    "    t_y = tree_values['POSITION_Y'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "\n",
    "    t_brightness = {}\n",
    "\n",
    "    for br in t_tree:\n",
    "        brch = t_tree[br]\n",
    "        x = t_x[br]\n",
    "        y = t_y[br]\n",
    "        time = t_time[br]\n",
    "        brightness = []\n",
    "    \n",
    "        for i in range(len(brch)):\n",
    "            if ((time[i] - 76200) >= 0) & ((time[i] - 76200) % 1800 == 0):\n",
    "                pos = (time[i] - 76200) // 1800\n",
    "                pic_base = pics[pos]\n",
    "                pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                pic_bg = cv2.circle(pic_bg, \n",
    "                                   (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                   int(diameter / PIXEL_INCH_RATIO),\n",
    "                                   (255, 255, 255),\n",
    "                                   -1)\n",
    "                pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                brightness.append(cv2.sumElems(pic)[0])\n",
    "                pics_intersect.append(pic)\n",
    "            else:\n",
    "                brightness.append(np.nan)\n",
    "            \n",
    "        t_brightness[br] = brightness\n",
    "    return t_brightness, np.array(pics_intersect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Cell Death Signal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_brightness_data(tree_id, tree, tree_values, reference_vid_path, diameter=12, save_vid=False, \n",
    "                              vid_path=None, out_path=None):\n",
    "    \"\"\"\n",
    "    This methods plots the progression of a the brightness coming from\n",
    "    processed cell death signal channel over time, which directly\n",
    "    corresponds to the strength of cell death signal.\n",
    "    \n",
    "    The method also offers the possibility to save a modified version of\n",
    "    time-lapsed video of cell death signal in which it only shows \n",
    "    the cells belonging to the tree of interest (as defined in 'tree_id')\n",
    "    \n",
    "    This method is somewhat related to 'extract_brightness()'. However,\n",
    "    this returns no value and only plots the results and saves\n",
    "    the modified video (if 'save_vid' is True).\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"visualizing tree %d\" % tree_id)\n",
    "\n",
    "    t_time = tree_values['POSITION_T'][tree_id]\n",
    "    t_x = tree_values['POSITION_X'][tree_id]\n",
    "    t_y = tree_values['POSITION_Y'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "    \n",
    "    if save_vid:\n",
    "        t_brightness, video = extract_brightness(tree_id, tree, tree_values, vid_path)\n",
    "    else:\n",
    "        t_brightness, _ = extract_brightness(tree_id, tree, tree_values, vid_path)\n",
    "    \n",
    "    for br in t_brightness:\n",
    "        brightness = np.array(t_brightness[br])\n",
    "        time = np.array(t_time[br])\n",
    "        time = time[~np.isnan(brightness)]\n",
    "        brightness= brightness[~np.isnan(brightness)]\n",
    "        pt.plot(time, brightness, label=\"%d\" % br)\n",
    "\n",
    "    pt.legend(loc='best')\n",
    "    pt.title(\"Cell line %d brightness measurement over time\" % tree_id)\n",
    "    pt.ylabel(\"Sum of cell's pixels' brightness (8-bit encoding)\")\n",
    "    pt.xlabel(\"Time (s)\")\n",
    "    pt.savefig(os.path.join(out_path_pics, \"%d-%d.pdf\" % (POSITION, tree_id)))\n",
    "    pt.clf()\n",
    "    \n",
    "    print(\"  plot written to %s\" % (os.path.join(out_path_pics, \"%d-%d.pdf\" % (POSITION, tree_id))))\n",
    "    \n",
    "    if save_vid:\n",
    "        imsave(os.path.join(out_path, 'test-%d.tiff' % tree_id), np.array(video))\n",
    "        print(\"  video written to %s\" % os.path.join(out_path, 'test-%d.tiff' % tree_id))\n",
    "        video = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate cell death information into cell trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_cell_death_signal(tree_id, \n",
    "                            tree, \n",
    "                            branch, \n",
    "                            tree_values, \n",
    "                            reference_vid_path, \n",
    "                            lookup_window=6,\n",
    "                            cell_death_value=3000):\n",
    "    \"\"\"\n",
    "    Incorporate cell death information coming from cell death signal channel\n",
    "    into the data. A cell is defined as death if:\n",
    "    \n",
    "        For at least twice within $lookup_window franes of out-focus\n",
    "        video the corresponding values of cell death signal are above\n",
    "        $cell_death_value\n",
    "        \n",
    "    Upon cell death determination, two things are done:\n",
    "    -   removal of all successors of the dead cell all the way to\n",
    "        the leaves.\n",
    "    -   update of measurement data of dead cell. All measurements\n",
    "        beyond the time of death are removed from the data.\n",
    "        \n",
    "    NOTE THAT the operation is done on deep-copied objects and hence\n",
    "    the original objects wouldn't be affected at all\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"processing tree %d\" % tree_id)\n",
    "\n",
    "    t_tree = tree[tree_id]\n",
    "    t_branch = branch[tree_id]\n",
    "    t_brightness, _ = extract_brightness(tree_id, tree, tree_values, reference_vid_path)\n",
    "    tree_values = copy.deepcopy(tree_values)\n",
    "    \n",
    "    # use cloned objects to not affect original objects\n",
    "    t_tree = copy.deepcopy(t_tree)\n",
    "    t_branch = copy.deepcopy(t_branch)\n",
    "\n",
    "    t_queue = construct_queue(t_branch, [], tree_id)\n",
    "\n",
    "    while len(t_queue) > 0:\n",
    "        \n",
    "        q = t_queue.pop(0)\n",
    "        print(\"  processing branch %d\" % q)\n",
    "        \n",
    "        brch = t_tree[q]\n",
    "        bghtns = t_brightness[q]\n",
    "    \n",
    "        death = None\n",
    "    \n",
    "        # find repeated signal brightness values > $cell_death_value\n",
    "        for i in range(len(bghtns)):\n",
    "            if (bghtns[i] > cell_death_value) and (i < len(bghtns) - lookup_window):\n",
    "            \n",
    "                # forward lookup for repeated death signal\n",
    "                for j in range(i + 1, min(len(bghtns), i + lookup_window + 1)):\n",
    "                    if bghtns[j] > cell_death_value:\n",
    "                        death = i\n",
    "                        break\n",
    "                \n",
    "                if death is not None:\n",
    "                    print(\"    branch %d marked dead\" % q)\n",
    "                \n",
    "                    \"\"\"\n",
    "                    change:\n",
    "                    - tree\n",
    "                    - branch\n",
    "                    - tree_values (x, y, etc)\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    # delete branch and its kids\n",
    "                    to_modify = construct_queue(t_branch, [], q)\n",
    "                    \n",
    "                    for tm in to_modify[1:]:\n",
    "                        # delete each kid of dead branch (quite unlikely but just incase)\n",
    "                        print(\"      removing {tree, brightness, measurement values} of  %d from tree\" % tm)\n",
    "                        t_tree = removekey(t_tree, tm)\n",
    "                        t_brightness = removekey(t_brightness, tm)\n",
    "                        if q in t_branch:\n",
    "                            t_branch = removekey(t_branch, q)\n",
    "                        for key in tree_values:\n",
    "                            tree_values[key][tree_id] = removekey(tree_values[key][tree_id], tm)\n",
    "                        t_queue.remove(tm)\n",
    "                \n",
    "                    # delete tailing measurements from branch and removing kids from branching conf\n",
    "                    print(\"    shortening {tree, brightness, measurement values} of %d at position %d (exclusive)\" % (q, death))\n",
    "                    t_tree[q] = t_tree[q][:i+1]\n",
    "                    t_brightness[q] = t_brightness[q][:i+1]\n",
    "                    if q in t_branch:\n",
    "                        t_branch = removekey(t_branch, q)\n",
    "                        \n",
    "                    for key in tree_values:\n",
    "                        tree_values[key][tree_id][q] = tree_values[key][tree_id][q][:i+1]\n",
    "                    break\n",
    "                \n",
    "    return t_tree, t_branch, t_brightness, tree_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out time-to-death statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_time_to_death_statistics(stats_path, tree_ids, div_times, ttd1s, ttd2s, append=True):\n",
    "    \"\"\"\n",
    "    Write out the computer time-to-death statistics\n",
    "    into the file given by 'stats_path'\n",
    "    \"\"\"\n",
    "\n",
    "    out = list(zip(*[[POSITION] * len(tree_ids), tree_ids, div_times, ttd1s, ttd2s]))\n",
    "    out = [list(i) for i in out]\n",
    "    outstr = []\n",
    "\n",
    "    for i in range(len(out)):\n",
    "        outstr.append([str(j) for j in out[i]])\n",
    "    \n",
    "    resstr = \"\"\n",
    "\n",
    "    for i in range(len(outstr)):\n",
    "        resstr += (\",\".join(outstr[i]) + \"\\n\")\n",
    "    \n",
    "    if append:\n",
    "        with open(stats_path, \"a\") as myfile:\n",
    "            myfile.write(resstr)\n",
    "    else:\n",
    "        with open(stats_path, \"w\") as myfile:\n",
    "            myfile.write(resstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all declared variables in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_all_variables():\n",
    "    \n",
    "    %reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Parsing TrackMate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for track in ba.TRACK_ID.unique():\n",
    "    sub = ba[ba.TRACK_ID == track]\n",
    "    pt.plot(range(sub.index.size), sub.EDGE_TIME - sub.EDGE_TIME.min())\n",
    "    \n",
    "frm = pt.gcf()\n",
    "frm.set_size_inches(16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree, branch = parse_trees(ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svals = extract_values(tree, sits, ['POSITION_T', 'POSITION_X', 'POSITION_Y', 'TOTAL_INTENSITY', 'QUALITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_id = list(tree.keys())[np.argmax([len(branch[x]) for x in tree.keys()])]\n",
    "plot_tree_value(tree_id, \"TOTAL_INTENSITY\", svals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Filter Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## WARNING: trees filtering by time affect other trees\n",
    "\n",
    "# tree_filtered, branch_filtered, svals_filtered = filter_trees_by_time(tree, branch, svals)\n",
    "tree, branch, svals = filter_trees_by_time(tree, branch, svals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Slit Asignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../test/eli-new-unsync-bf-%d/in-focus/before' % POSITION\n",
    "impath = 'bf_in-focusxy%dc1c1-mask.tif' % POSITION\n",
    "imorigpath = 'bf_in-focusxy%dc1c1.tif' % POSITION\n",
    "immask = '../test/eli-new-unsync-bf-%d/out-focus/merged/merged.tif' % POSITION\n",
    "\n",
    "im = cv2.imread(os.path.join(path, impath))\n",
    "imorig = cv2.imread(os.path.join(path, imorigpath))\n",
    "immask = cv2.imread(immask)\n",
    "\n",
    "gray= cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "im2, contours, hierarchy  = cv2.findContours(gray,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cts, cts_size, cts_size_al = get_contour(os.path.join(path, impath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.hist(cts_size, bins=20)\n",
    "pt.title(\"Distribution of slit sizes (pixels)\")\n",
    "pt.xlabel(\"Slit size (pixels)\")\n",
    "pt.ylabel(\"# slits\")\n",
    "pt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assocs, occuppancy = assign_tree_to_contours(svals, cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"# of trees in slit: %d\" % assocs[~assocs.SLIT_ID.isnull()].index.size)\n",
    "print(\"Ratio  of cell lines not identified to specific slit: %f\" % (assocs[assocs.SLIT_ID.isnull()].index.size / assocs.index.size))\n",
    "print(\"ratio of slit not associated with any cell lineage: %f\" % (occuppancy[occuppancy == 0].size / occuppancy.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.hist(list(occuppancy))\n",
    "pt.xticks(range(max(occuppancy) + 1))\n",
    "pt.xlabel(\"Occupancy\")\n",
    "pt.ylabel(\"# Slits\")\n",
    "pt.title(\"Occupancy Histogram (all)\")\n",
    "\n",
    "# pt.gcf().set_size_inches(8, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Valid Trees Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dev pipeline\n",
    "doubly_placed_tree = get_trees_by_placement(assocs, placement=2)\n",
    "print(\"# of doubly-placed trees: %d\" % len(doubly_placed_tree))\n",
    "\n",
    "singly_placed_tree = get_trees_by_placement(assocs, placement=1)\n",
    "print(\"# of singly-placed trees: %d\" % len(singly_placed_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Embed Signal Information Into Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree_unpruned = copy.deepcopy(tree)\n",
    "branch_unpruned = copy.deepcopy(branch)\n",
    "svals_unpruned = copy.deepcopy(svals)\n",
    "\n",
    "for t in (singly_placed_tree + doubly_placed_tree):\n",
    "    t_tree, t_branch, _, this_svals = embed_cell_death_signal(t, tree, branch, svals, caspase_tiff_path)\n",
    "    tree[t] = t_tree\n",
    "    branch[t] = t_branch\n",
    "    svals = this_svals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  VI. Iterative filtering of valid trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "singly_placed_tree_divs, \\\n",
    "    invalid_trees_nodiv, \\\n",
    "    invalid_trees_morethan1div, \\\n",
    "    tree_one_div, \\\n",
    "    tree_one_div_div_times, \\\n",
    "    tree_divbfrtreatment, \\\n",
    "    tree_divbfrtreatment_div_times, \\\n",
    "    tree_divbfrtreatment_last_time_1, \\\n",
    "    tree_divbfrtreatment_last_time_2, \\\n",
    "    tree_deathaftertreatment, \\\n",
    "    tree_deathaftertreatment_div_times, \\\n",
    "    last_time_1, \\\n",
    "    last_time_2 = filter_invalid_trees(singly_placed_tree, tree, branch, svals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot number of divisions of valid trees\n",
    "\n",
    "pt.hist(singly_placed_tree_divs, bins=max(singly_placed_tree_divs))\n",
    "pt.title(\"Histogram of branch numbers per cell tree\")\n",
    "pt.ylabel(\"# Cell trees\")\n",
    "pt.xlabel(\"# Branches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CHANGED\n",
    "\n",
    "pt.hist(tree_one_div_div_times)\n",
    "pt.title(\"Distribution of tree's division times\")\n",
    "pt.xlabel(\"Division time\")\n",
    "pt.axvline(126 * TIME_UNIT_FACTOR, c='red')\n",
    "pt.gcf().set_size_inches(10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.hist(tree_divbfrtreatment_last_time_1 + tree_divbfrtreatment_last_time_2)\n",
    "pt.title(\"Distribution of tree branch's last measurement time\")\n",
    "pt.xlabel(\"Branch's last measurement time\")\n",
    "pt.axvline(126 * TIME_UNIT_FACTOR, c='red')\n",
    "pt.gcf().set_size_inches(10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high = int(max(tree_divbfrtreatment_div_times + tree_divbfrtreatment_last_time_1 + tree_divbfrtreatment_last_time_2))\n",
    "pt.scatter(tree_divbfrtreatment_div_times, tree_divbfrtreatment_last_time_1)\n",
    "pt.scatter(tree_divbfrtreatment_div_times, tree_divbfrtreatment_last_time_2)\n",
    "pt.plot(list(range(high)), list(range(high)))\n",
    "\n",
    "pt.title(\"Scatter plot of division time vs branch's last measurement time\")\n",
    "pt.xlabel(\"Tree's division time\")\n",
    "pt.ylabel(\"Branch's last measurement time\")\n",
    "pt.axhline(126 * TIME_UNIT_FACTOR, c='red')\n",
    "pt.gcf().set_size_inches(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_deathaftertreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttd1 = [(x - 126 * TIME_UNIT_FACTOR) for x in last_time_1]\n",
    "ttd2 = [(x - 126 * TIME_UNIT_FACTOR) for x in last_time_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.scatter(tree_deathaftertreatment_div_times, ttd1)\n",
    "pt.scatter(tree_deathaftertreatment_div_times, ttd2)\n",
    "pt.title(\"Scatter plot of division time vs Time-to-death\")\n",
    "pt.xlabel(\"Division time\")\n",
    "pt.ylabel(\"Time to death\")\n",
    "pt.gcf().set_size_inches(10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Export Tree Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_time_to_death_statistics(exit_dat, tree_deathaftertreatment, tree_deathaftertreatment_div_times, ttd1, ttd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Export TIFFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## draw contours with $num cell lineages\n",
    "\n",
    "num = 0\n",
    "\n",
    "ctsprint = [cts[x] for x in list(np.argwhere(occuppancy == num).T[[0]][0])]\n",
    "\n",
    "imc = imorig.copy()\n",
    "cv2.drawContours(imc, ctsprint, -1, (255, 0, 0), 4)\n",
    "cv2.imwrite(os.path.join(path, 'im_contours_%d.tiff' % num), imc);\n",
    "\n",
    "imc = immask.copy()\n",
    "cv2.drawContours(imc, ctsprint, -1, (255, 0, 0), 4)\n",
    "cv2.imwrite(os.path.join(path, 'im_contours_%d_mask.tiff' % num), imc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## draw all spots in T=0\n",
    "\n",
    "imc = imorig.copy()\n",
    "for sid in ss[ss.POSITION_T == 0]['ID']:\n",
    "    x = ss[ss.ID == sid]['POSITION_X'].values[0] / PIXEL_INCH_RATIO\n",
    "    y = ss[ss.ID == sid]['POSITION_Y'].values[0] / PIXEL_INCH_RATIO\n",
    "    cv2.circle(imc, (int(x) + 3, int(y) + 3), 4, (255, 255, 0), -1)\n",
    "cv2.imwrite(os.path.join(path, 'all_t0.tiff'), imc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## draw contours with $num cell lineages\n",
    "\n",
    "num = 1\n",
    "\n",
    "ctsprint = [cts[x] for x in list(np.argwhere(occuppancy == num).T[[0]][0])]\n",
    "\n",
    "imc = imorig.copy()\n",
    "cv2.drawContours(imc, ctsprint, -1, (255, 0, 0), 4)\n",
    "for tr in list(np.argwhere(occuppancy == num).T[[0]][0]):\n",
    "    pths = assocs[assocs.SLIT_ID == tr].CELL_LINE.tolist()\n",
    "    for pth in pths:\n",
    "        y = svals['POSITION_Y'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        x = svals['POSITION_X'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        cv2.circle(imc, (int(x), int(y)), 4, (0, 255, 0), -1)\n",
    "#         cv2.putText(imc,\"track %d: coord (%d, %d)\" % (pth, int(x), int(y)), \n",
    "#                     (int(x), int(y)), cv2.FONT_HERSHEY_COMPLEX, 0.8,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imwrite(os.path.join(path, 'im_contours_%d.tiff' % num), imc);\n",
    "\n",
    "imc = immask.copy()\n",
    "cv2.drawContours(imc, ctsprint, -1, (255, 0, 0), 4)\n",
    "for tr in list(np.argwhere(occuppancy == num).T[[0]][0]):\n",
    "    pths = assocs[assocs.SLIT_ID == tr].CELL_LINE.tolist()\n",
    "    for pth in pths:\n",
    "        y = svals['POSITION_Y'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        x = svals['POSITION_X'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        cv2.circle(imc, (int(x), int(y)), 4, (0, 255, 0), -1)\n",
    "#         cv2.putText(imc,\"track %d: coord (%d, %d)\" % (pth, int(x), int(y)), \n",
    "#                     (int(x), int(y)), cv2.FONT_HERSHEY_COMPLEX, 0.8,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imwrite(os.path.join(path, 'im_contours_%d_mask.tiff' % num), imc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## draw contours with $num cell lineages\n",
    "\n",
    "num = 2\n",
    "\n",
    "ctsprint = [cts[x] for x in list(np.argwhere(occuppancy == num).T[[0]][0])]\n",
    "\n",
    "imc = imorig.copy()\n",
    "cv2.drawContours(imc, ctsprint, -1, (255, 0, 0), 4)\n",
    "for tr in list(np.argwhere(occuppancy == num).T[[0]][0]):\n",
    "    pths = assocs[assocs.SLIT_ID == tr].CELL_LINE.tolist()\n",
    "    for pth in pths:\n",
    "        y = svals['POSITION_Y'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        x = svals['POSITION_X'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        cv2.circle(imc, (int(x), int(y)), 4, (0, 255, 0), -1)\n",
    "#         cv2.putText(imc,\"track %d: coord (%d, %d)\" % (pth, int(x), int(y)), \n",
    "#                     (int(x), int(y)), cv2.FONT_HERSHEY_COMPLEX, 0.8,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imwrite(os.path.join(path, 'im_contours_%d.tiff' % num), imc);\n",
    "\n",
    "imc = immask.copy()\n",
    "cv2.drawContours(imc, ctsprint, -1, (255, 0, 0), 4)\n",
    "for tr in list(np.argwhere(occuppancy == num).T[[0]][0]):\n",
    "    pths = assocs[assocs.SLIT_ID == tr].CELL_LINE.tolist()\n",
    "    for pth in pths:\n",
    "        y = svals['POSITION_Y'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        x = svals['POSITION_X'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        cv2.circle(imc, (int(x), int(y)), 4, (0, 255, 0), -1)\n",
    "#         cv2.putText(imc,\"track %d: coord (%d, %d)\" % (pth, int(x), int(y)), \n",
    "#                     (int(x), int(y)), cv2.FONT_HERSHEY_COMPLEX, 0.8,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imwrite(os.path.join(path, 'im_contours_%d_mask.tiff' % num), imc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## draw contours with $num cell lineages\n",
    "\n",
    "num = 3\n",
    "\n",
    "ctsprint = [cts[x] for x in list(np.argwhere(occuppancy == num).T[[0]][0])]\n",
    "\n",
    "imc = imorig.copy()\n",
    "cv2.drawContours(imc, ctsprint, -1, (255, 0, 0), 4)\n",
    "for tr in list(np.argwhere(occuppancy == num).T[[0]][0]):\n",
    "    pths = assocs[assocs.SLIT_ID == tr].CELL_LINE.tolist()\n",
    "    for pth in pths:\n",
    "        y = svals['POSITION_Y'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        x = svals['POSITION_X'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        cv2.circle(imc, (int(x), int(y)), 4, (0, 255, 0), -1)\n",
    "#         cv2.putText(imc,\"track %d: coord (%d, %d)\" % (pth, int(x), int(y)), \n",
    "#                     (int(x), int(y)), cv2.FONT_HERSHEY_COMPLEX, 0.8,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imwrite(os.path.join(path, 'im_contours_%d.tiff' % num), imc);\n",
    "\n",
    "imc = immask.copy()\n",
    "cv2.drawContours(imc, ctsprint, -1, (255, 0, 0), 4)\n",
    "for tr in list(np.argwhere(occuppancy == num).T[[0]][0]):\n",
    "    pths = assocs[assocs.SLIT_ID == tr].CELL_LINE.tolist()\n",
    "    for pth in pths:\n",
    "        y = svals['POSITION_Y'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        x = svals['POSITION_X'][pth][pth][0] / PIXEL_INCH_RATIO\n",
    "        cv2.circle(imc, (int(x), int(y)), 4, (0, 255, 0), -1)\n",
    "#         cv2.putText(imc,\"track %d: coord (%d, %d)\" % (pth, int(x), int(y)), \n",
    "#                     (int(x), int(y)), cv2.FONT_HERSHEY_COMPLEX, 0.8,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imwrite(os.path.join(path, 'im_contours_%d_mask.tiff' % num), imc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Sanity Check of Recognized Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE for sanity check always use the unmodified data, i.e.:\n",
    "- tree_unpruned\n",
    "- branch_unpruned\n",
    "- svals_unpruned\n",
    "\"\"\"\n",
    "\n",
    "## export video of valid trees\n",
    "\n",
    "for t in tree_deathaftertreatment:\n",
    "    export_snapshot([t], \n",
    "                    tree_assoc=assocs, \n",
    "                    slit_contours=cts, \n",
    "                    tree=tree_unpruned, \n",
    "                    branch=branch_unpruned, \n",
    "                    tree_values=svals_unpruned, \n",
    "                    tiff_path='../test/eli-new-unsync-bf-%d/out-focus/merged/merged.tif' % POSITION, \n",
    "                    out_path='../test/eli-new-unsync-bf-%d/out-focus/merged/single_analysis/valid/' % POSITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## export video of invalid trees\n",
    "\n",
    "for t in doubly_placed_tree:\n",
    "    slit_id = assocs[assocs.CELL_LINE == t]['SLIT_ID'].values[0]\n",
    "    export_snapshot_slit(slit_id,\n",
    "                         tree_assoc=assocs, \n",
    "                         slit_contours=cts, \n",
    "                         tree=tree_unpruned,\n",
    "                         branch=branch_unpruned, \n",
    "                         tree_values=svals_unpruned, \n",
    "                         tiff_path='../test/eli-new-unsync-bf-%d/out-focus/merged/merged.tif' % POSITION, \n",
    "                         out_path='../test/eli-new-unsync-bf-%d/out-focus/merged/single_analysis/invalid/doublyplaced/' % POSITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## export video of invalid trees\n",
    "\n",
    "for t in invalid_trees_nodiv:\n",
    "    export_snapshot([t],\n",
    "                    tree_assoc=assocs, \n",
    "                    slit_contours=cts, \n",
    "                    tree=tree_unpruned, \n",
    "                    branch=branch_unpruned, \n",
    "                    tree_values=svals_unpruned, \n",
    "                    tiff_path='../test/eli-new-unsync-bf-%d/out-focus/merged/merged.tif' % POSITION, \n",
    "                    out_path='../test/eli-new-unsync-bf-%d/out-focus/merged/single_analysis/invalid/nodiv/' % POSITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## export video of invalid trees\n",
    "\n",
    "for t in invalid_trees_morethan1div:\n",
    "    export_snapshot([t],\n",
    "                    tree_assoc=assocs, \n",
    "                    slit_contours=cts, \n",
    "                    tree=tree_unpruned, \n",
    "                    branch=branch_unpruned, \n",
    "                    tree_values=svals_unpruned, \n",
    "                    tiff_path='../test/eli-new-unsync-bf-%d/out-focus/merged/merged.tif' % POSITION, \n",
    "                    out_path='../test/eli-new-unsync-bf-%d/out-focus/merged/single_analysis/invalid/morethan1div/' % POSITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## export video of invalid trees\n",
    "\n",
    "invalid_trees_divaftertreatment = set(tree_one_div) - set(tree_divbfrtreatment)\n",
    "\n",
    "for t in invalid_trees_divaftertreatment:\n",
    "    export_snapshot([t],\n",
    "                    tree_assoc=assocs, \n",
    "                    slit_contours=cts, \n",
    "                    tree=tree_unpruned, \n",
    "                    branch=branch_unpruned, \n",
    "                    tree_values=svals_unpruned, \n",
    "                    tiff_path='../test/eli-new-unsync-bf-%d/out-focus/merged/merged.tif' % POSITION, \n",
    "                    out_path='../test/eli-new-unsync-bf-%d/out-focus/merged/single_analysis/invalid/divaftertreatment/' % POSITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## export video of invalid trees\n",
    "\n",
    "invalid_trees_deathbeforetreatment = list(set(tree_divbfrtreatment) - set(tree_deathaftertreatment))\n",
    "\n",
    "for t in invalid_trees_deathbeforetreatment:\n",
    "    export_snapshot([t], \n",
    "                    tree_assoc=assocs, \n",
    "                    slit_contours=cts, \n",
    "                    tree=tree_unpruned,\n",
    "                    branch=branch_unpruned,\n",
    "                    tree_values=svals_unpruned, \n",
    "                    tiff_path='../test/eli-new-unsync-bf-%d/out-focus/merged/merged.tif' % POSITION, \n",
    "                    out_path='../test/eli-new-unsync-bf-%d/out-focus/merged/single_analysis/invalid/deathbeforetreatmen/' % POSITION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIII. Death Signal Embedding and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment conf:\n",
    "out-focus = 21 hrs (126 slides a 10 mins) + 24 hrs (144 slides a 10 mins)\n",
    "caspacin = 24 hrs (48 slides a 30 mins)\n",
    "first slide of caspacin refers to (126 + 1) * 600 = 76200\n",
    "\n",
    "cell death cut-off value: 1000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caspase_path = \"../test/eli-new-unsync-bf-%d/caspase/\" % POSITION\n",
    "tiff_path = os.path.join(caspase_path, \"caspasexy%dc1_sub.tif\" % POSITION)\n",
    "tiff_path_intersection = os.path.join(caspase_path, \"caspasexy%dc1_inter.tif\" % POSITION)\n",
    "\n",
    "out_path_pics = \"../results/pics/unsyn/\"\n",
    "if not os.path.exists(out_path_pics):\n",
    "    os.makedirs(out_path_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tr in tree_deathaftertreatment:\n",
    "\n",
    "    t_brightness, _ = extract_brightness(tr, tree_unpruned, svals_unpruned, tiff_path)\n",
    "    t_time = svals_unpruned['POSITION_T'][tr]\n",
    "\n",
    "    for br in t_brightness:\n",
    "        brightness = np.array(t_brightness[br])\n",
    "        time = np.array(t_time[br])\n",
    "        time = time[~np.isnan(brightness)]\n",
    "        brightness= brightness[~np.isnan(brightness)]\n",
    "        pt.plot(time, brightness, label=\"%d-%d\" % (tr, br))\n",
    "        \n",
    "pt.legend(loc='best')\n",
    "pt.title(\"Progression of cell lines' brightness measurement over time (pre-prunning)\")\n",
    "pt.ylabel(\"Sum of cell's pixels' brightness (8-bit encoding)\")\n",
    "pt.xlabel(\"Time (s)\")\n",
    "pt.axhline(3500, c='r', linestyle='--')\n",
    "\n",
    "fr = pt.gcf()\n",
    "fr.set_size_inches(10, 10)\n",
    "\n",
    "pt.savefig(os.path.join(out_path_pics, \"%d.pdf\" % POSITION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tr in tree_deathaftertreatment:\n",
    "\n",
    "    t_brightness, _ = extract_brightness(tr, tree, svals, tiff_path)\n",
    "    t_time = svals['POSITION_T'][tr]\n",
    "\n",
    "    for br in t_brightness:\n",
    "        brightness = np.array(t_brightness[br])\n",
    "        time = np.array(t_time[br])\n",
    "        time = time[~np.isnan(brightness)]\n",
    "        brightness= brightness[~np.isnan(brightness)]\n",
    "        pt.plot(time, brightness, label=\"%d-%d\" % (tr, br))\n",
    "        \n",
    "pt.legend(loc='best')\n",
    "pt.title(\"Progression of cell lines' brightness measurement over time (post-prunning)\")\n",
    "pt.ylabel(\"Sum of cell's pixels' brightness (8-bit encoding)\")\n",
    "pt.xlabel(\"Time (s)\")\n",
    "pt.axhline(3500, c='r', linestyle='--')\n",
    "\n",
    "fr = pt.gcf()\n",
    "fr.set_size_inches(10, 10)\n",
    "\n",
    "pt.savefig(os.path.join(out_path_pics, \"%d.pdf\" % POSITION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for vt in tree_deathaftertreatment:\n",
    "    visualize_brightness_data(vt, tree_unpruned, svals_unpruned, tiff_path, save_vid=True, vid_path=tiff_path, out_path=caspase_path)\n",
    "    pt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "delete_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IX. Measurement of various slit recognition methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    }
   ],
   "source": [
    "pth = '../test/eli-new-unsync-bf-47/in-focus/before/bf_in-focusxy47c1c1_brightness-basic-robust-fill.tif'\n",
    "imin = cv2.imread(pth)\n",
    "ctrout = recognize_slits(imin)\n",
    "print(len(ctrout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277\n"
     ]
    }
   ],
   "source": [
    "pth = '../test/eli-new-unsync-bf-47/in-focus/before/bf_in-focusxy47c1c1-mask.tif'\n",
    "imin = cv2.imread(pth)\n",
    "ctrout = recognize_slits(imin)\n",
    "print(len(ctrout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n"
     ]
    }
   ],
   "source": [
    "pth = '../test/eli-new-unsync-bf-47/in-focus/before/test-slit-segmentation/04-fill-holes.tif'\n",
    "imin = cv2.imread(pth)\n",
    "ctrout = recognize_slits(imin)\n",
    "print(len(ctrout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
